{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjwqaG57qGrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f81aab-7c5e-4994-d51a-223f8728a233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.12/dist-packages (0.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (7.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.8.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.14)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.5.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.25.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.27.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.23)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.0.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.11.1)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.9.0.20251008)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers captum scikit-learn matplotlib seaborn torch pandas numpy ipywidgets\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import re\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    AutoModelForSequenceClassification\n",
        ")\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "# from captum.attr import Saliency, Occlusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKLAH7YM0iU-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995,
          "referenced_widgets": [
            "07ae3da755c749f98f821e7add16987d",
            "af8bdb3547d2496f9e51ab4446068fb4",
            "7f75fb32d5ca4326b0ed7a195944c494",
            "24d8212fbbdc49bba994151c44f7b979",
            "7abcb6a99dfe4d548a0dd2d0ed4bddae",
            "1a4e1ab553844473ac255e69191577f4",
            "431526763a9041e3b1255c0c5a61b553",
            "a6e9d529b6d943a198a9088f7b9ff6ea",
            "26aee59a512d454fb8c22bc78d6b3389",
            "7e5b233326094e95b7fcdc207bf70124",
            "59c24bbff9d54aa2a7fd13a4931a92ed",
            "a312a1b9f7564fe9a69af0f4e3aeef12",
            "bb20727feab244eebf07bdc359fb92f3",
            "91e1b8df0dec4ce28629edd2d1508378",
            "3abef1ab0eab4c62ba49b2844688136f",
            "5bd34c412dc246c6b6d8ab879feeb933",
            "c3af99932bad49c8a93857f1d0aef96f",
            "20ba4fb7895b4c959d2513d0324de64a",
            "a10fb516a23643889c0d269399b4d87a",
            "1b61018d938a4fc891a2ae0397cd38d7",
            "d48efb65a4c84ad1a274cb14ebf9980d",
            "35c0926d72f6416486a4af203e630616",
            "8b0761ad2caa46eb863acb1f7996c0f8",
            "70689b99b371426ebf294a3d7f87aee1",
            "bdd319f8d652420290dda79edd7eab88",
            "bf01820ddf1848239e27363a06eb23d1",
            "9f4e6f358f574b179506b2ec0364c75f",
            "ba5d77aef59a43cf8bc9bb7f7ef41c1a",
            "3b205a11f9414ecaad52557490f7348b",
            "07f508a5ed9a42cd8dbf4d175973f98a",
            "afe70e4c263e4b318bc155f5eadca26a",
            "6af22a9660ec43ad803fbfa9b3c3a698",
            "c8bd34cd73054cffa4ca4ea31364936a",
            "c0487fda4651475988cdca9a4b61aed2",
            "0d9e05c866c24c7aaa303a61e294e998",
            "dd2e166cfe84491896dd204ad129c708",
            "81d139ac38d04fd1a976808360ee17b4",
            "558829597bf341f5a183e67088721cf9",
            "794cdd6f93af41128b6321d823f4e188",
            "548faa36a4a84c13b0b88033ad5b35a8",
            "e3ee69ed0d1c42478233bd1975d52ee4",
            "996ba88a2ddd4be7b10f373fc5954de6",
            "0b930c7814fa416c9e649d1a1bf7a277",
            "e44e8e22561a442dba3a2c67bad4931a"
          ]
        },
        "outputId": "ce8d9d09-4304-4ca4-dbab-dd0134874e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/407 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07ae3da755c749f98f821e7add16987d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a312a1b9f7564fe9a69af0f4e3aeef12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b0761ad2caa46eb863acb1f7996c0f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0487fda4651475988cdca9a4b61aed2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at tae898/emoberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaModel(\n",
              "  (embeddings): RobertaEmbeddings(\n",
              "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "    (token_type_embeddings): Embedding(1, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): RobertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): RobertaPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# 1. Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "df     = pd.read_csv(\"/content/train_sent_emo_cleaned_processed.csv\", encoding=\"utf-8\")\n",
        "\n",
        "MODEL_NAME = \"tae898/emoberta-base\"\n",
        "tok        = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model      = AutoModel.from_pretrained(MODEL_NAME, output_hidden_states=True)\n",
        "model.to(device).eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6fdc6ad8926c451ca93231e3c051b753",
            "313effa8d28746ee8adc12d05a05e658",
            "7930f6cb68634da1a992dd8433feef43",
            "e8aff838f262450b85fe408be5482226",
            "2cfbaf63157a488db596a6d2760fb0b4",
            "f40766baea764001b72cbb1e4c0f74d0",
            "8e97d3f8a3ae41918b1dc34fbdbfec6b",
            "675044b42d1a4b4d8ea01f1263dedd10",
            "946614f365c447cd9c3f3e6ed8e31db6",
            "5c9eb588e2fb4106a8224fae9ae4d1a9",
            "f4810b9434284606858e17196dbb31f9"
          ]
        },
        "id": "nzn7rpJBvSQX",
        "outputId": "ac99b329-4806-40b1-8ae3-83df952ad871"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fdc6ad8926c451ca93231e3c051b753"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# ── TOKEN-LEVEL EMBEDDINGS ────────────────────────────────────────────────\n",
        "\n",
        "# Extract every token’s last-layer embedding\n",
        "all_embs = []\n",
        "with torch.no_grad():\n",
        "    for sent in df[\"Utterance\"]:\n",
        "        out      = model(**tok(sent, return_tensors=\"pt\").to(device))\n",
        "        hidden   = out.hidden_states[-1].squeeze(0)       # (seq_len, hidden_dim)\n",
        "        token_ids = tok(sent, return_tensors=\"pt\")[\"input_ids\"].squeeze().tolist()\n",
        "        # skip [CLS] & [SEP]\n",
        "        for emb in hidden[1:len(token_ids)-1]:\n",
        "            all_embs.append(emb.cpu().numpy())\n",
        "\n",
        "X_tok = np.vstack(all_embs)  # (total_tokens, 768)\n",
        "\n",
        "# Reduce to 50D, then t-SNE → 2D\n",
        "X50_tok    = PCA(n_components=50, random_state=42).fit_transform(X_tok)\n",
        "coords_tok = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\",\n",
        "                  perplexity=30, random_state=42).fit_transform(X50_tok)\n",
        "\n",
        "# Option A: plot all tokens in grey\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(coords_tok[:,0], coords_tok[:,1],\n",
        "            color=\"lightgrey\", alpha=0.5, s=3)\n",
        "plt.title(\"Token Embeddings (t-SNE) — no emotion labels\")\n",
        "plt.xlabel(\"Dim 1\"); plt.ylabel(\"Dim 2\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Option B: cluster tokens unsupervised and color by cluster\n",
        "kmeans_tok = KMeans(n_clusters=7, random_state=42).fit(X50_tok)\n",
        "labs_tok   = kmeans_tok.labels_\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "scatter = plt.scatter(coords_tok[:,0], coords_tok[:,1],\n",
        "                      c=labs_tok, cmap=\"tab10\", alpha=0.6, s=3)\n",
        "plt.title(\"Token Embeddings (t-SNE) — colored by KMeans cluster\")\n",
        "plt.xlabel(\"Dim 1\"); plt.ylabel(\"Dim 2\")\n",
        "plt.colorbar(scatter, ticks=range(7)).set_label(\"Cluster ID\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ── SENTENCE-LEVEL (CLS) EMBEDDINGS ───────────────────────────────────────\n",
        "\n",
        "# Extract CLS embedding per sentence\n",
        "sent_embs, sent_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for sent, lbl in zip(df[\"Utterance\"], df[\"Emotion\"]):\n",
        "        out    = model(**tok(sent, return_tensors=\"pt\").to(device))\n",
        "        cls    = out.hidden_states[-1][:,0,:].squeeze(0).cpu().numpy()\n",
        "        sent_embs.append(cls)\n",
        "        sent_labels.append(lbl)\n",
        "\n",
        "X_sent = np.vstack(sent_embs)\n",
        "y_sent = np.array(sent_labels)\n",
        "\n",
        "# t-SNE → 2D (after optional PCA to 50D)\n",
        "X50_sent    = PCA(n_components=50, random_state=42).fit_transform(X_sent)\n",
        "coords_sent = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\",\n",
        "                   perplexity=30, random_state=24).fit_transform(X50_sent)\n",
        "\n",
        "# map emotions → ints for coloring\n",
        "emotions = sorted(df[\"Emotion\"].unique())\n",
        "e2i      = {e:i for i,e in enumerate(emotions)}\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(coords_sent[:,0], coords_sent[:,1],\n",
        "            c=[e2i[l] for l in y_sent],\n",
        "            cmap=\"tab10\", alpha=0.8, s=25, edgecolor=\"k\", linewidth=0.3)\n",
        "plt.title(\"Sentence (CLS) Embeddings (t-SNE) — colored by true emotion\")\n",
        "plt.xlabel(\"Dim 1\"); plt.ylabel(\"Dim 2\")\n",
        "cbar = plt.colorbar(ticks=range(len(emotions)))\n",
        "cbar.ax.set_yticklabels(emotions)\n",
        "cbar.set_label(\"Emotion\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leIln3toU6cB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from captum.attr import Saliency\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# 1) Load your fine-tuned ERC model and tokenizer\n",
        "MODEL_NAME = \"tae898/emoberta-base\"   # your checkpoint\n",
        "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer  = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model      = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(device).eval()\n",
        "\n",
        "# 2) The core saliency‐computation function using Captum’s API exactly\n",
        "def get_saliency_captum(text, target_label=None):\n",
        "    # a) Tokenize\n",
        "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    input_ids      = enc[\"input_ids\"]      # [1, seq_len]\n",
        "    attention_mask = enc[\"attention_mask\"] # [1, seq_len]\n",
        "\n",
        "    # b) Get embeddings and enable gradients\n",
        "    embeds = model.get_input_embeddings()(input_ids)  # [1, seq_len, hidden_dim]\n",
        "    embeds.requires_grad_()\n",
        "\n",
        "    # c) Define a forward function that only takes embeddings\n",
        "    def forward_fn(inputs_embeds):\n",
        "        outputs = model(\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            attention_mask=attention_mask\n",
        "        ).logits  # [1, num_labels]\n",
        "        if target_label is None:\n",
        "            return outputs.max(dim=1)[0]        # predicted logit\n",
        "        return outputs[:, target_label]         # specific class logit\n",
        "\n",
        "    # d) Compute saliency on that forward_fn\n",
        "    saliency = Saliency(forward_fn)\n",
        "    attributions = saliency.attribute(embeds)  # [1, seq_len, hidden_dim]\n",
        "\n",
        "    # e) Aggregate across hidden_dim → one score per token\n",
        "    token_scores = attributions.abs() \\\n",
        "                               .sum(dim=-1) \\\n",
        "                               .squeeze(0) \\\n",
        "                               .cpu().detach().numpy()  # [seq_len]\n",
        "\n",
        "    # f) Map back to token strings\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
        "    return tokens, token_scores\n",
        "\n",
        "# 3) Load the dataset\n",
        "df = pd.read_csv(\"train_sent_emo_cleaned_processed.csv\", encoding=\"utf-8\")\n",
        "\n",
        "# --- Part 1: Local explanation for a single utterance ---\n",
        "idx   = 0  # pick whichever row you want\n",
        "text  = df[\"Utterance\"].iloc[idx]\n",
        "label = df[\"Emotion\"].iloc[idx]\n",
        "\n",
        "tokens, scores = get_saliency_captum(text)\n",
        "# normalize to [0,1] for coloring\n",
        "norm = (scores - scores.min()) / (scores.ptp() + 1e-20)\n",
        "cmap = plt.get_cmap(\"Reds\")\n",
        "\n",
        "plt.figure(figsize=(12,2))\n",
        "plt.axis(\"off\")\n",
        "x = 0.01\n",
        "for tok, v in zip(tokens, norm):\n",
        "    plt.text(x, 0.5, tok,\n",
        "             fontsize=12,\n",
        "             bbox=dict(facecolor=cmap(v), edgecolor=\"none\", pad=0.3))\n",
        "    x += len(tok) * 0.013\n",
        "plt.title(f\"Saliency Map for Utterance #{idx} (Emotion: {label})\")\n",
        "plt.show()\n",
        "\n",
        "# --- Part 2: Global explanation per emotion ---\n",
        "emotion_token_scores = {e: defaultdict(list) for e in df[\"Emotion\"].unique()}\n",
        "N_PER_EMO = 50  # sample size per emotion to limit memory\n",
        "\n",
        "for emo, group in df.groupby(\"Emotion\"):\n",
        "    texts = group[\"Utterance\"] \\\n",
        "                  .sample(min(len(group), N_PER_EMO), random_state=42)\n",
        "    for t in texts:\n",
        "        toks, scs = get_saliency_captum(t)\n",
        "        for tk, sc in zip(toks, scs):\n",
        "            emotion_token_scores[emo][tk].append(sc)\n",
        "\n",
        "# Build a DataFrame of token, count, and average saliency per emotion\n",
        "records = []\n",
        "for emo, tok_dict in emotion_token_scores.items():\n",
        "    for tk, lst in tok_dict.items():\n",
        "        if len(lst) < 5:               # skip very rare tokens\n",
        "            continue\n",
        "        records.append({\n",
        "            \"emotion\": emo,\n",
        "            \"token\": tk,\n",
        "            \"count\": len(lst),\n",
        "            \"avg_saliency\": np.mean(lst)\n",
        "        })\n",
        "\n",
        "df_all = pd.DataFrame(records)\n",
        "\n",
        "# For each emotion, pick top 10 tokens by avg_saliency\n",
        "df_top = (\n",
        "    df_all\n",
        "      .sort_values([\"emotion\",\"avg_saliency\"], ascending=[True, False])\n",
        "      .groupby(\"emotion\")\n",
        "      .head(10)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(df_top)\n",
        "\n",
        "# Bar‐chart for each emotion\n",
        "for emo in df_top[\"emotion\"].unique():\n",
        "    sub = df_top[df_top[\"emotion\"] == emo]\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.barh(sub[\"token\"][::-1], sub[\"avg_saliency\"][::-1])\n",
        "    plt.title(f\"Top 10 Tokens for Emotion: {emo}\")\n",
        "    plt.xlabel(\"Average Saliency\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPq0tJ8ZWn4B"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Pivot σε DataFrame\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Υποθέτουμε ότι έχεις ήδη:\n",
        "# df_top_per_emo με στήλες [\"emotion\",\"token\",\"avg_saliency\"]\n",
        "\n",
        "# Φτιάχνουμε τον πίνακα heatmap\n",
        "heat = df_top.pivot(index=\"emotion\", columns=\"token\", values=\"avg_saliency\").fillna(0)\n",
        "\n",
        "# Δημιούργησε τη φιγούρα με κατάλληλο μέγεθος\n",
        "plt.figure(figsize=(14, 6))  # π.χ. 14 ίντσες πλάτος, 6 ύψος\n",
        "ax = sns.heatmap(\n",
        "    heat,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"Reds\",\n",
        "    linewidths=0.5,\n",
        "    cbar_kws={\"shrink\": 0.8, \"label\": \"Avg Saliency\"}\n",
        ")\n",
        "\n",
        "# Στροφές & μεγέθη ετικετών\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=10)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=12)\n",
        "\n",
        "plt.title(\"Heatmap of Avg Saliency per Token per Emotion\", fontsize=14, pad=12)\n",
        "plt.xlabel(\"Token\", fontsize=12)\n",
        "plt.ylabel(\"Emotion\", fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Eh3YSV7X834"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ── 1) Recompute top-5 tokens per emotion ──────────────────────────────────\n",
        "# Assume you have `df_all` from your global explanation step:\n",
        "# df_all = DataFrame with columns [\"emotion\",\"token\",\"count\",\"avg_saliency\"]\n",
        "\n",
        "# Filter out very rare tokens\n",
        "df_filtered = df_all[df_all[\"count\"] >= 5]\n",
        "\n",
        "# Sort descending by avg_saliency within each emotion\n",
        "df_sorted = df_filtered.sort_values(\n",
        "    [\"emotion\", \"avg_saliency\"], ascending=[True, False]\n",
        ")\n",
        "\n",
        "# Take top 5 per emotion\n",
        "df_top5 = df_sorted.groupby(\"emotion\").head(5).reset_index(drop=True)\n",
        "\n",
        "# ── 2) Pivot to wide format for heatmap ─────────────────────────────────────\n",
        "heat = df_top5.pivot(\n",
        "    index=\"emotion\",\n",
        "    columns=\"token\",\n",
        "    values=\"avg_saliency\"\n",
        ").fillna(0)\n",
        "\n",
        "# ── 3) Plot styled heatmap ────────────────────────────────────────────────\n",
        "plt.figure(figsize=(14, 6))\n",
        "ax = sns.heatmap(\n",
        "    heat,\n",
        "    annot=True,            # show values\n",
        "    fmt=\".1f\",             # one decimal place\n",
        "    cmap=\"YlOrRd\",         # yellow→red colormap\n",
        "    linewidths=0.8,        # cell borders\n",
        "    linecolor=\"gray\",\n",
        "    cbar_kws={\"shrink\": 0.7, \"label\": \"Avg Saliency\"}\n",
        ")\n",
        "\n",
        "# Improve axis labels\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=45,\n",
        "    ha=\"right\",\n",
        "    fontsize=10\n",
        ")\n",
        "ax.set_yticklabels(\n",
        "    ax.get_yticklabels(),\n",
        "    rotation=0,\n",
        "    fontsize=12\n",
        ")\n",
        "\n",
        "plt.title(\n",
        "    \"Top 5 Tokens by Avg Saliency per Emotion\",\n",
        "    fontsize=16,\n",
        "    pad=12\n",
        ")\n",
        "plt.xlabel(\"Token\", fontsize=14)\n",
        "plt.ylabel(\"Emotion\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmC2HFn8YQVe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ── 1) Compute overall mean saliency per token ────────────────────────────\n",
        "# Assume `df_all` exists with [\"emotion\",\"token\",\"count\",\"avg_saliency\"]\n",
        "# Filter out very rare tokens for stability\n",
        "df_filtered = df_all[df_all[\"count\"] >= 5]\n",
        "\n",
        "# Group by token across all emotions\n",
        "df_global = (\n",
        "    df_filtered\n",
        "      .groupby(\"token\")\n",
        "      .agg(mean_saliency_all=(\"avg_saliency\",\"mean\"))\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "# Pick the TOP_N tokens by this overall mean\n",
        "TOP_N = 10\n",
        "top_tokens = df_global.nlargest(TOP_N, \"mean_saliency_all\")[\"token\"].tolist()\n",
        "\n",
        "# ── 2) Build heatmap matrix (emotions × top_tokens) ───────────────────────\n",
        "# Pivot your original per-emotion data for only these tokens\n",
        "heat = (\n",
        "    df_filtered[df_filtered[\"token\"].isin(top_tokens)]\n",
        "      .pivot(index=\"emotion\", columns=\"token\", values=\"avg_saliency\")\n",
        "      .reindex(columns=top_tokens)   # ensure token order matches ranking\n",
        "      .fillna(0)\n",
        ")\n",
        "\n",
        "# ── 3) Plot styled heatmap ────────────────────────────────────────────────\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.heatmap(\n",
        "    heat,\n",
        "    annot=True,\n",
        "    fmt=\".1f\",\n",
        "    cmap=\"YlGnBu\",\n",
        "    linewidths=0.8,\n",
        "    linecolor=\"gray\",\n",
        "    cbar_kws={\"shrink\":0.7, \"label\":\"Avg Saliency\"}\n",
        ")\n",
        "\n",
        "# Tidy up labels\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=11)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=12)\n",
        "\n",
        "plt.title(f\"Heatmap of Avg Saliency per Emotion for Top {TOP_N} Global Tokens\", fontsize=16, pad=12)\n",
        "plt.xlabel(\"Token\", fontsize=14)\n",
        "plt.ylabel(\"Emotion\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iwb6x2LJYrG1"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Διαλέγουμε ένα συγκεκριμένο emotion (π.χ. \"joy\")\n",
        "emo = \"joy\"\n",
        "# Παίρνουμε τα scores για τα top-tokens αυτού του emotion από το token_saliencies\n",
        "data = []\n",
        "for tok, scores in emotion_token_scores[emo].items():\n",
        "    if len(scores)>=5:\n",
        "        for s in scores:\n",
        "            data.append({\"token\": tok, \"saliency\": s})\n",
        "df_box = pd.DataFrame(data)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.violinplot(x=\"token\", y=\"saliency\", data=df_box, inner=\"quartile\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(f\"Violin plot of saliency-scores for emotion '{emo}'\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbYc5W_PbDPX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 2) Saliency function (per Captum docs)\n",
        "def get_saliency(text):\n",
        "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    input_ids      = enc[\"input_ids\"]       # [1, seq_len]\n",
        "    attention_mask = enc[\"attention_mask\"]  # [1, seq_len]\n",
        "\n",
        "    embeds = model.get_input_embeddings()(input_ids)\n",
        "    embeds.requires_grad_()\n",
        "\n",
        "    def forward_emb(inputs_embeds):\n",
        "        logits = model(\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            attention_mask=attention_mask\n",
        "        ).logits\n",
        "        # return logit of the predicted class\n",
        "        return logits.max(dim=1)[0]\n",
        "\n",
        "    sal = Saliency(forward_emb)\n",
        "    atts = sal.attribute(embeds)  # [1, seq_len, hidden_dim]\n",
        "    scores = atts.abs().sum(dim=-1).squeeze(0).cpu().detach().numpy()\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
        "    return tokens, scores\n",
        "\n",
        "# 3) Prediction helper\n",
        "def predict_proba(text):\n",
        "    enc   = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    logits = model(**enc).logits\n",
        "    return F.softmax(logits, dim=-1).squeeze(0).cpu().detach().numpy()\n",
        "\n",
        "# 4) Select one utterance\n",
        "df = pd.read_csv(\"train_sent_emo_cleaned_processed.csv\", encoding=\"utf-8\")\n",
        "idx = np.random.randint(len(df))    # or set idx = 0,1,...\n",
        "text = df[\"Utterance\"].iloc[idx]\n",
        "true_label = df[\"Emotion\"].iloc[idx]\n",
        "print(f\"Utterance #{idx} (True: {true_label}):\\n{text}\\n\")\n",
        "\n",
        "# 5) Compute saliency and original prediction\n",
        "tokens, saliency_scores = get_saliency(text)\n",
        "probs = predict_proba(text)\n",
        "pred_idx   = int(probs.argmax())\n",
        "pred_label = model.config.id2label[pred_idx]\n",
        "orig_prob  = float(probs[pred_idx])\n",
        "print(f\"Predicted: {pred_label} (p={orig_prob:.3f})\\n\")\n",
        "\n",
        "# 6) For every token (excluding special), mask and recompute\n",
        "results = []\n",
        "for i, (tok, sc) in enumerate(zip(tokens, saliency_scores)):\n",
        "    if tok in tokenizer.all_special_tokens:\n",
        "        continue\n",
        "    masked = tokens.copy()\n",
        "    masked[i] = tokenizer.mask_token\n",
        "    masked_text = tokenizer.convert_tokens_to_string(masked)\n",
        "    masked_prob = predict_proba(masked_text)[pred_idx]\n",
        "    results.append({\n",
        "        \"token\": tok,\n",
        "        \"position\": i,\n",
        "        \"saliency\": round(float(sc),4),\n",
        "        \"orig_prob\": round(orig_prob,4),\n",
        "        \"masked_prob\": round(float(masked_prob),4),\n",
        "        \"delta\": round(orig_prob - float(masked_prob),4)\n",
        "    })\n",
        "\n",
        "df_cf = pd.DataFrame(results)\n",
        "print(df_cf)\n",
        "\n",
        "# 7) Plot Δ for all tokens\n",
        "plt.figure(figsize=(max(8, len(df_cf)*0.4), 4))\n",
        "plt.bar(df_cf[\"token\"], df_cf[\"delta\"], color=\"salmon\", edgecolor=\"k\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"Δ Probability\")\n",
        "plt.title(f\"Counterfactual Δ for all tokens (Predicted: {pred_label})\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FJ0cHV5cnQv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 5) Interactive explain function with Matplotlib\n",
        "def explain_utterance(idx):\n",
        "    clear_output(wait=True)\n",
        "    text = df[\"Utterance\"].iloc[idx]\n",
        "    true = df[\"Emotion\"].iloc[idx]\n",
        "    toks, sal = get_saliency(text)\n",
        "    probs     = predict_proba(text)\n",
        "    pred_idx  = int(probs.argmax())\n",
        "    pred_lbl  = model.config.id2label[pred_idx]\n",
        "    orig_p    = float(probs[pred_idx])\n",
        "\n",
        "    # build counterfactual Δ for every non-special token\n",
        "    rows = []\n",
        "    for i,(tok,sc) in enumerate(zip(toks, sal)):\n",
        "        if tok in tokenizer.all_special_tokens:\n",
        "            continue\n",
        "        masked = toks.copy()\n",
        "        masked[i] = tokenizer.mask_token\n",
        "        mp = predict_proba(tokenizer.convert_tokens_to_string(masked))[pred_idx]\n",
        "        rows.append((tok, sc, orig_p - float(mp)))\n",
        "    df_cf = pd.DataFrame(rows, columns=[\"token\",\"saliency\",\"delta\"])\n",
        "\n",
        "    # display utterance + preds\n",
        "    display(HTML(f\"<b>Utterance #{idx}</b> (True: <i>{true}</i>)<br/>{text}\"))\n",
        "    display(HTML(f\"<b>Predicted:</b> {pred_lbl} (p={orig_p:.3f})\"))\n",
        "\n",
        "    # plot bar chart\n",
        "    plt.figure(figsize=(max(8, len(df_cf)*0.5), 4))\n",
        "    plt.bar(df_cf[\"token\"], df_cf[\"delta\"], color=\"salmon\", edgecolor=\"k\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.ylabel(\"Δ Probability\")\n",
        "    plt.title(f\"Counterfactual Δ for Utterance #{idx} ({pred_lbl})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 6) Hook up the slider\n",
        "utter_slider = widgets.IntSlider(\n",
        "    value=0, min=0, max=len(df)-1, step=1,\n",
        "    description=\"Utterance idx:\"\n",
        ")\n",
        "widgets.interact(explain_utterance, idx=utter_slider)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "groblX-0gZSx"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 4) Interactive explain with slider + dropdown\n",
        "def explain(idx, mask_token):\n",
        "    clear_output(wait=True)\n",
        "    text = df[\"Utterance\"].iloc[idx]\n",
        "    true = df[\"Emotion\"].iloc[idx]\n",
        "    toks, sal = get_saliency(text)\n",
        "    probs = predict_proba(text)\n",
        "    pred_idx = int(probs.argmax()); pred_lbl = model.config.id2label[pred_idx]\n",
        "    orig_p   = float(probs[pred_idx])\n",
        "\n",
        "    # Show utterance & prediction\n",
        "    display(HTML(f\"<b>Utterance #{idx}</b> (True: <i>{true}</i>)<br/>{text}\"))\n",
        "    display(HTML(f\"<b>Predicted:</b> {pred_lbl} (p={orig_p:.3f})\"))\n",
        "\n",
        "    # Compute Δ for the selected token\n",
        "    # (or if mask_token is None, show full bar chart)\n",
        "    if mask_token is not None:\n",
        "        # find first occurrence of that token\n",
        "        positions = [i for i,t in enumerate(toks) if t==mask_token]\n",
        "        if not positions:\n",
        "            print(f\"Token {mask_token!r} not in this utterance.\")\n",
        "        else:\n",
        "            i = positions[0]\n",
        "            m = toks.copy(); m[i] = tokenizer.mask_token\n",
        "            mp = predict_proba(tokenizer.convert_tokens_to_string(m))[pred_idx]\n",
        "            delta = orig_p - float(mp)\n",
        "            display(HTML(\n",
        "                f\"<b>Masking token</b> <code>{mask_token}</code> at position {i}:<br>\"\n",
        "                f\"New p({pred_lbl}) = {mp:.3f} &rarr; Δ = {delta:.3f}\"\n",
        "            ))\n",
        "    else:\n",
        "        # show full bar chart of Δ for all tokens\n",
        "        records = []\n",
        "        for i,(tok,sc) in enumerate(zip(toks, sal)):\n",
        "            if tok in tokenizer.all_special_tokens: continue\n",
        "            m = toks.copy(); m[i]=tokenizer.mask_token\n",
        "            mp = predict_proba(tokenizer.convert_tokens_to_string(m))[pred_idx]\n",
        "            records.append((tok, orig_p - float(mp)))\n",
        "        df_cf = pd.DataFrame(records, columns=[\"token\",\"delta\"])\n",
        "        plt.figure(figsize=(max(8,len(df_cf)*0.4),3))\n",
        "        plt.bar(df_cf[\"token\"], df_cf[\"delta\"], color=\"salmon\", edgecolor=\"k\")\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.ylabel(\"Δ Probability\")\n",
        "        plt.title(f\"Counterfactual Δ for all tokens ({pred_lbl})\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Widgets\n",
        "utter_idx = widgets.IntSlider(0, 0, len(df)-1, description=\"Utterance\")\n",
        "token_dd  = widgets.Dropdown(options=[None], description=\"Mask Token\")\n",
        "\n",
        "def update_tokens(*args):\n",
        "    toks,_ = get_saliency(df[\"Utterance\"].iloc[utter_idx.value])\n",
        "    # only unique non-special tokens\n",
        "    opts = [None] + [t for t in dict.fromkeys(toks) if t not in tokenizer.all_special_tokens]\n",
        "    token_dd.options = opts\n",
        "\n",
        "utter_idx.observe(update_tokens, names=\"value\")\n",
        "\n",
        "ui = widgets.HBox([utter_idx, token_dd])\n",
        "out = widgets.interactive_output(explain, {\"idx\": utter_idx, \"mask_token\": token_dd})\n",
        "\n",
        "display(ui, out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ybR69EuhDTQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 2) Merge BPE/subword tokens back into full words, skipping special tokens\n",
        "def merge_subwords(tokens):\n",
        "    words, positions = [], []\n",
        "    cur_w, cur_pos   = \"\", []\n",
        "    for i, tok in enumerate(tokens):\n",
        "        # skip any special tokens\n",
        "        if tok in tokenizer.all_special_tokens:\n",
        "            continue\n",
        "        # detect start of a new word\n",
        "        if tok.startswith(\"Ġ\") or tok.startswith(\"▁\"):\n",
        "            if cur_w:\n",
        "                words.append(cur_w.rstrip(\".,;!?\"))\n",
        "                positions.append(cur_pos)\n",
        "            cur_w = tok.lstrip(\"Ġ▁\")\n",
        "            cur_pos = [i]\n",
        "        else:\n",
        "            cur_w += tok\n",
        "            cur_pos.append(i)\n",
        "    # append last word\n",
        "    if cur_w:\n",
        "        words.append(cur_w.rstrip(\".,;!?\"))\n",
        "        positions.append(cur_pos)\n",
        "    return words, positions\n",
        "\n",
        "# 3) Compute saliency scores per token (sum of absolute gradients)\n",
        "def get_saliency(text):\n",
        "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    input_ids, attention_mask = enc[\"input_ids\"], enc[\"attention_mask\"]\n",
        "    # get embeddings and enable gradients\n",
        "    embeds = model.get_input_embeddings()(input_ids)\n",
        "    embeds.requires_grad_()\n",
        "    # define forward on embeddings\n",
        "    def forward_emb(inputs_embeds):\n",
        "        logits = model(inputs_embeds=inputs_embeds, attention_mask=attention_mask).logits\n",
        "        # we take the logit of the predicted class\n",
        "        return logits.max(dim=1)[0]\n",
        "    # compute saliency\n",
        "    sal = Saliency(forward_emb)\n",
        "    atts = sal.attribute(embeds)                  # [1, seq_len, hidden_dim]\n",
        "    scores = atts.abs().sum(dim=-1).squeeze(0)     # [seq_len]\n",
        "    toks   = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
        "    return toks, scores.cpu().numpy()\n",
        "\n",
        "# 4) Helper to get model probabilities\n",
        "def predict_proba(text):\n",
        "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**enc).logits\n",
        "    return F.softmax(logits, dim=-1).squeeze(0).cpu().numpy()\n",
        "\n",
        "# 5) Load your dataset\n",
        "df = pd.read_csv(\"train_sent_emo_cleaned_processed.csv\", encoding=\"utf-8\")\n",
        "\n",
        "# 6) Pick an utterance to explain\n",
        "idx  = 0  # change to any row index\n",
        "text = df[\"Utterance\"].iloc[idx]\n",
        "true = df[\"Emotion\"].iloc[idx]\n",
        "print(f\"Utterance #{idx} (True emotion: {true}):\\n{text}\\n\")\n",
        "\n",
        "# 7) Compute token saliency and merge into words\n",
        "toks, sal_scores = get_saliency(text)\n",
        "words, positions = merge_subwords(toks)\n",
        "\n",
        "# 8) Original prediction\n",
        "probs     = predict_proba(text)\n",
        "pred_idx  = int(np.argmax(probs))\n",
        "pred_lbl  = model.config.id2label[pred_idx]\n",
        "orig_prob = float(probs[pred_idx])\n",
        "print(f\"Predicted: {pred_lbl} (p = {orig_prob:.3f})\\n\")\n",
        "\n",
        "# 9) Build a DataFrame of counterfactual effects per word\n",
        "records = []\n",
        "for w, pos_list in zip(words, positions):\n",
        "    # sum saliency of all subwords for that word\n",
        "    word_saliency = float(sal_scores[pos_list].sum())\n",
        "    # mask all subwords\n",
        "    masked = toks.copy()\n",
        "    for p in pos_list:\n",
        "        masked[p] = tokenizer.mask_token\n",
        "    masked_text = tokenizer.convert_tokens_to_string(masked)\n",
        "    masked_prob = predict_proba(masked_text)[pred_idx]\n",
        "    delta       = orig_prob - float(masked_prob)\n",
        "    records.append({\n",
        "        \"word\": w,\n",
        "        \"saliency\": word_saliency,\n",
        "        \"orig_prob\": orig_prob,\n",
        "        \"masked_prob\": float(masked_prob),\n",
        "        \"delta\": delta\n",
        "    })\n",
        "\n",
        "df_explain = pd.DataFrame(records)\n",
        "print(df_explain)\n",
        "\n",
        "# 10) Plot Δ for each word\n",
        "plt.figure(figsize=(max(8, len(df_explain)*0.5), 4))\n",
        "plt.bar(df_explain[\"word\"], df_explain[\"delta\"], color=\"salmon\", edgecolor=\"k\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"Δ Probability\")\n",
        "plt.title(f\"Counterfactual Δ per Word for Utterance #{idx} ({pred_lbl})\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMQVwKf7h3xX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 2) Compute saliency per token\n",
        "def get_saliency(text):\n",
        "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    input_ids = enc[\"input_ids\"]       # [1, seq_len]\n",
        "    mask      = enc[\"attention_mask\"]  # [1, seq_len]\n",
        "\n",
        "    # get embeddings + enable grad\n",
        "    embeds = model.get_input_embeddings()(input_ids)\n",
        "    embeds.requires_grad_()\n",
        "\n",
        "    # forward on embeddings only\n",
        "    def forward_emb(inputs_embeds):\n",
        "        logits = model(inputs_embeds=inputs_embeds, attention_mask=mask).logits\n",
        "        return logits.max(dim=1)[0]  # predicted-class logit\n",
        "\n",
        "    sal = Saliency(forward_emb)\n",
        "    atts = sal.attribute(embeds)                # [1, seq_len, hidden_dim]\n",
        "    scores = atts.abs().sum(dim=-1).squeeze(0)   # [seq_len]\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
        "    return input_ids.squeeze().tolist(), tokens, scores.cpu().numpy()\n",
        "\n",
        "# 3) Predict helper\n",
        "def predict_proba(text):\n",
        "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**enc).logits\n",
        "    return F.softmax(logits, dim=-1).squeeze(0).cpu().numpy()\n",
        "\n",
        "# 4) Merge subword tokens into words based on token text and original indices\n",
        "def merge_to_words(tokens):\n",
        "    words = []\n",
        "    # Store lists of *original token indices* for each word\n",
        "    word_token_indices = []\n",
        "    current_indices = []\n",
        "    current_word_text = \"\"\n",
        "\n",
        "    # Iterate through tokens with their original indices\n",
        "    for i, tok in enumerate(tokens):\n",
        "        # Skip special tokens\n",
        "        if tok in tokenizer.all_special_tokens:\n",
        "            # If we were building a word, flush it before skipping\n",
        "            if current_word_text:\n",
        "                words.append(current_word_text.strip())\n",
        "                word_token_indices.append(current_indices)\n",
        "                current_word_text = \"\"\n",
        "                current_indices = []\n",
        "            continue\n",
        "\n",
        "        # If the token indicates a new word starts (e.g., has a leading space prefix),\n",
        "        # and we were already building a word, flush the previous word first.\n",
        "        # This heuristic works reasonably well for many tokenizers.\n",
        "        if tok.startswith(\"Ġ\") or tok.startswith(\" \"):\n",
        "            if current_word_text:\n",
        "                words.append(current_word_text.strip())\n",
        "                word_token_indices.append(current_indices)\n",
        "                current_word_text = \"\"\n",
        "                current_indices = []\n",
        "            # Start a new word\n",
        "            current_word_text = tok.lstrip(\"Ġ \") # Remove leading space\n",
        "            current_indices = [i]\n",
        "        else:\n",
        "            # Append to the current word\n",
        "            current_word_text += tok\n",
        "            current_indices.append(i)\n",
        "\n",
        "    # After the loop, append the last accumulated word if any\n",
        "    if current_word_text:\n",
        "        words.append(current_word_text.strip())\n",
        "        word_token_indices.append(current_indices)\n",
        "\n",
        "    return words, word_token_indices\n",
        "\n",
        "\n",
        "# 5) Load dataset\n",
        "df = pd.read_csv(\"train_sent_emo_cleaned_processed.csv\", encoding=\"utf-8\")\n",
        "\n",
        "# 6) Pick an utterance\n",
        "idx  = 0\n",
        "text = df[\"Utterance\"].iloc[idx]\n",
        "true = df[\"Emotion\"].iloc[idx]\n",
        "print(f\"Utterance #{idx} (True: {true}):\\n{text}\\n\")\n",
        "\n",
        "# 7) Compute saliency & merge to words\n",
        "input_ids, toks, sal_scores = get_saliency(text)\n",
        "# Use the original tokens list for merging\n",
        "words, word_token_indices = merge_to_words(toks)\n",
        "\n",
        "\n",
        "# 8) Original prediction\n",
        "probs     = predict_proba(text)\n",
        "pred_idx  = int(np.argmax(probs))\n",
        "pred_lbl  = model.config.id2label[pred_idx]\n",
        "orig_prob = float(probs[pred_idx])\n",
        "print(f\"Predicted: {pred_lbl} (p={orig_prob:.3f})\\n\")\n",
        "\n",
        "# 9) Counterfactual per word\n",
        "records = []\n",
        "for w, token_indices in zip(words, word_token_indices):\n",
        "    # sum token-level saliency for the tokens belonging to this word\n",
        "    # Use the original indices to index into the sal_scores array\n",
        "    word_sal = sal_scores[token_indices].sum()\n",
        "\n",
        "    # Mask all subword tokens that constitute this word in the original input_ids\n",
        "    masked_ids = input_ids.copy()\n",
        "    # Find the actual indices in the *full* input_ids list for these tokens\n",
        "    # This assumes the order of `toks` corresponds directly to `input_ids`\n",
        "    # Which is true for the output of tokenizer(..., return_tensors=\"pt\")\n",
        "    for original_token_index in token_indices:\n",
        "         # Replace the token ID at the original index with the mask token ID\n",
        "         masked_ids[original_token_index] = tokenizer.mask_token_id\n",
        "\n",
        "    masked_text = tokenizer.decode(masked_ids, skip_special_tokens=True)\n",
        "    masked_prob = predict_proba(masked_text)[pred_idx]\n",
        "    records.append({\n",
        "        \"word\": w,\n",
        "        \"saliency\": word_sal,\n",
        "        \"orig_prob\": orig_prob,\n",
        "        \"masked_prob\": float(masked_prob),\n",
        "        \"delta\": orig_prob - float(masked_prob)\n",
        "    })\n",
        "\n",
        "df_explain = pd.DataFrame(records)\n",
        "print(df_explain)\n",
        "\n",
        "# 10) Plot\n",
        "plt.figure(figsize=(max(8, len(df_explain)*0.5), 4))\n",
        "plt.bar(df_explain[\"word\"], df_explain[\"delta\"], color=\"salmon\", edgecolor=\"k\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"Δ Probability\")\n",
        "plt.title(f\"Counterfactual Δ per Word for Utterance #{idx} ({pred_lbl})\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9Hq9QfEiDwc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 2) Compute token‐level saliency + return offsets\n",
        "def get_saliency_and_offsets(text):\n",
        "    enc = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        return_offsets_mapping=True\n",
        "    ).to(device)\n",
        "\n",
        "    input_ids       = enc[\"input_ids\"]           # [1, seq_len]\n",
        "    attention_mask  = enc[\"attention_mask\"]      # [1, seq_len]\n",
        "    offsets         = enc[\"offset_mapping\"][0].cpu().tolist()  # list of (start,end)\n",
        "    tokens          = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
        "\n",
        "    # embeddings + grad\n",
        "    embeds = model.get_input_embeddings()(input_ids)\n",
        "    embeds.requires_grad_()\n",
        "\n",
        "    def forward_emb(inputs_embeds):\n",
        "        logits = model(\n",
        "          inputs_embeds=inputs_embeds,\n",
        "          attention_mask=attention_mask\n",
        "        ).logits\n",
        "        return logits.max(dim=1)[0]\n",
        "\n",
        "    sal = Saliency(forward_emb)\n",
        "    atts = sal.attribute(embeds)                   # [1, seq_len, hidden_dim]\n",
        "    scores = atts.abs().sum(dim=-1).squeeze(0)      # [seq_len]\n",
        "\n",
        "    return tokens, scores.cpu().numpy(), offsets\n",
        "\n",
        "# 3) Group token indices by original words via regex on text\n",
        "def group_tokens_by_word(text, offsets):\n",
        "    # find spans of each whitespace-separated word\n",
        "    spans = [(m.start(), m.end(), m.group()) for m in re.finditer(r'\\S+', text)]\n",
        "    token2word = {}\n",
        "    for tidx, (start, end) in enumerate(offsets):\n",
        "        # skip special tokens (offsets of (0,0))\n",
        "        if start == 0 and end == 0:\n",
        "            continue\n",
        "        # find which span this token starts in\n",
        "        for widx, (wstart, wend, wstr) in enumerate(spans):\n",
        "            if start >= wstart and start < wend:\n",
        "                token2word.setdefault(widx, []).append(tidx)\n",
        "                break\n",
        "\n",
        "    words = []\n",
        "    positions = []\n",
        "    for widx, toks_idxs in sorted(token2word.items()):\n",
        "        _, _, wstr = spans[widx]\n",
        "        words.append(wstr)\n",
        "        positions.append(toks_idxs)\n",
        "    return words, positions\n",
        "\n",
        "# 4) Prediction helper\n",
        "def predict_proba(text):\n",
        "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**enc).logits\n",
        "    return F.softmax(logits, dim=-1).squeeze(0).cpu().numpy()\n",
        "\n",
        "# 5) Load your dataset\n",
        "df = pd.read_csv(\"train_sent_emo_cleaned_processed.csv\", encoding=\"utf-8\")\n",
        "\n",
        "# 6) Pick an utterance\n",
        "idx  = 0  # change as needed\n",
        "text = df[\"Utterance\"].iloc[idx]\n",
        "true = df[\"Emotion\"].iloc[idx]\n",
        "print(f\"Utterance #{idx} (True: {true}):\\n{text}\\n\")\n",
        "\n",
        "# 7) Saliency & offsets → group into words\n",
        "tokens, sal_scores, offsets = get_saliency_and_offsets(text)\n",
        "words, word_positions       = group_tokens_by_word(text, offsets)\n",
        "\n",
        "# 8) Original prediction\n",
        "probs     = predict_proba(text)\n",
        "pred_idx  = int(np.argmax(probs))\n",
        "pred_lbl  = model.config.id2label[pred_idx]\n",
        "orig_prob = float(probs[pred_idx])\n",
        "print(f\"Predicted: {pred_lbl} (p = {orig_prob:.3f})\\n\")\n",
        "\n",
        "# 9) Counterfactual per word\n",
        "records = []\n",
        "for w, pos_list in zip(words, word_positions):\n",
        "    # sum the saliency scores for all subwords of this word\n",
        "    word_saliency = float(sal_scores[pos_list].sum())\n",
        "    # mask those positions\n",
        "    input_ids = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)[\"input_ids\"][0].tolist()\n",
        "    for tidx in pos_list:\n",
        "        input_ids[tidx] = tokenizer.mask_token_id\n",
        "    masked_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "    masked_prob = predict_proba(masked_text)[pred_idx]\n",
        "    delta       = orig_prob - float(masked_prob)\n",
        "\n",
        "    records.append({\n",
        "        \"word\": w,\n",
        "        \"saliency\": word_saliency,\n",
        "        \"orig_prob\": orig_prob,\n",
        "        \"masked_prob\": float(masked_prob),\n",
        "        \"delta\": delta\n",
        "    })\n",
        "\n",
        "df_explain = pd.DataFrame(records)\n",
        "print(df_explain)\n",
        "\n",
        "# 10) Plot Δ for each word\n",
        "plt.figure(figsize=(max(8, len(df_explain)*0.5), 4))\n",
        "plt.bar(df_explain[\"word\"], df_explain[\"delta\"], color=\"salmon\", edgecolor=\"k\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"Δ Probability\")\n",
        "plt.title(f\"Counterfactual Δ per Word for Utterance #{idx} ({pred_lbl})\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jns2PCyXi4zO"
      },
      "outputs": [],
      "source": [
        "# 0) pip install captum transformers torch pandas numpy matplotlib ipywidgets\n",
        "\n",
        "import re\n",
        "import torch, torch.nn.functional as F\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from captum.attr  import Saliency\n",
        "\n",
        "# 1) Load model & fast tokenizer (for offsets)\n",
        "MODEL_NAME = \"tae898/emoberta-base\"\n",
        "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer  = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model      = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(device).eval()\n",
        "\n",
        "# 2) Reconstruct words using offset mapping and split punctuation separately\n",
        "def reconstruct_words(text):\n",
        "    enc = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        return_offsets_mapping=True,\n",
        "        truncation=True,\n",
        "        padding=\"longest\"\n",
        "    )\n",
        "    offsets = enc[\"offset_mapping\"][0].tolist()    # list of (start,end)\n",
        "    # find spans: words (\\w+) or punctuation sequences ([^\\w\\s]+)\n",
        "    spans = [(m.start(), m.end(), m.group())\n",
        "             for m in re.finditer(r\"\\w+|[^\\w\\s]+\", text)]\n",
        "    token2word = {}\n",
        "    for tidx, (start, end) in enumerate(offsets):\n",
        "        # skip special tokens (offset (0,0))\n",
        "        if start == end == 0:\n",
        "            continue\n",
        "        # assign this token to the word span it falls into\n",
        "        for widx, (wstart, wend, _) in enumerate(spans):\n",
        "            if start >= wstart and start < wend:\n",
        "                token2word.setdefault(widx, []).append(tidx)\n",
        "                break\n",
        "    # build lists of words and token indices\n",
        "    words, positions = [], []\n",
        "    for widx in sorted(token2word):\n",
        "        _, _, wstr = spans[widx]\n",
        "        words.append(wstr)\n",
        "        positions.append(token2word[widx])\n",
        "    return words, positions\n",
        "\n",
        "# 3) Saliency & predict helpers\n",
        "def get_saliency(text):\n",
        "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    ids, mask = enc[\"input_ids\"], enc[\"attention_mask\"]\n",
        "    embeds = model.get_input_embeddings()(ids); embeds.requires_grad_()\n",
        "    def fwd(e): return model(inputs_embeds=e, attention_mask=mask).logits.max(1)[0]\n",
        "    atts = Saliency(fwd).attribute(embeds)\n",
        "    scores = atts.abs().sum(-1).squeeze(0).cpu().numpy()\n",
        "    toks   = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "    return toks, scores\n",
        "\n",
        "def predict_proba(text):\n",
        "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**enc).logits\n",
        "    return F.softmax(logits,dim=-1).squeeze(0).cpu().numpy()\n",
        "\n",
        "# 4) Load data\n",
        "df = pd.read_csv(\"train_sent_emo_cleaned_processed.csv\", encoding=\"utf-8\")\n",
        "\n",
        "# 5) Interactive explain: using WORDS instead of raw tokens\n",
        "def explain(idx, mask_word):\n",
        "    clear_output(wait=True)\n",
        "    text = df[\"Utterance\"].iloc[idx]\n",
        "    true = df[\"Emotion\"].iloc[idx]\n",
        "    toks, sal = get_saliency(text)\n",
        "    words, positions = reconstruct_words(text)\n",
        "    probs    = predict_proba(text)\n",
        "    pred_idx = int(probs.argmax())\n",
        "    pred_lbl = model.config.id2label[pred_idx]\n",
        "    orig_p   = float(probs[pred_idx])\n",
        "\n",
        "    display(HTML(f\"<b>Utterance #{idx}</b> (True: <i>{true}</i>)<br/>{text}\"))\n",
        "    display(HTML(f\"<b>Predicted:</b> {pred_lbl} (p={orig_p:.3f})\"))\n",
        "\n",
        "    if mask_word is not None:\n",
        "        if mask_word not in words:\n",
        "            print(f\"Word {mask_word!r} not found.\")\n",
        "        else:\n",
        "            wi = words.index(mask_word)\n",
        "            pos_list = positions[wi]\n",
        "            masked_tokens = toks.copy()\n",
        "            for p in pos_list:\n",
        "                masked_tokens[p] = tokenizer.mask_token\n",
        "            masked_text = tokenizer.convert_tokens_to_string(masked_tokens)\n",
        "            mp = predict_proba(masked_text)[pred_idx]\n",
        "            delta = orig_p - float(mp)\n",
        "            display(HTML(\n",
        "                f\"<b>Masking word</b> <code>{mask_word}</code>:<br>\"\n",
        "                f\"New p({pred_lbl}) = {mp:.3f} → Δ = {delta:.3f}\"\n",
        "            ))\n",
        "    else:\n",
        "        records = []\n",
        "        for w, pos_list in zip(words, positions):\n",
        "            if any(t in tokenizer.all_special_tokens for t in [toks[p] for p in pos_list]):\n",
        "                continue\n",
        "            masked_tokens = toks.copy()\n",
        "            for p in pos_list:\n",
        "                masked_tokens[p] = tokenizer.mask_token\n",
        "            mp = predict_proba(tokenizer.convert_tokens_to_string(masked_tokens))[pred_idx]\n",
        "            records.append((w, orig_p - float(mp)))\n",
        "        df_cf = pd.DataFrame(records, columns=[\"word\",\"delta\"])\n",
        "        plt.figure(figsize=(max(8, len(df_cf)*0.3), 3))\n",
        "        plt.bar(df_cf[\"word\"], df_cf[\"delta\"], color=\"salmon\", edgecolor=\"k\")\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.ylabel(\"Δ Probability\")\n",
        "        plt.title(f\"Counterfactual Δ per Word ({pred_lbl})\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Widgets\n",
        "utter_idx = widgets.IntSlider(0, 0, len(df)-1, description=\"Utterance\")\n",
        "word_dd = widgets.Dropdown(options=[None], description=\"Mask Word\")\n",
        "\n",
        "def update_word_options(*args):\n",
        "    words, _ = reconstruct_words(df[\"Utterance\"].iloc[utter_idx.value])\n",
        "    word_dd.options = [None] + words\n",
        "\n",
        "utter_idx.observe(update_word_options, names=\"value\")\n",
        "update_word_options()\n",
        "\n",
        "ui  = widgets.HBox([utter_idx, word_dd])\n",
        "out = widgets.interactive_output(explain, {\"idx\": utter_idx, \"mask_word\": word_dd})\n",
        "\n",
        "display(ui, out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnuxnUggphRw"
      },
      "outputs": [],
      "source": [
        "from captum.attr import Occlusion\n",
        "\n",
        "# 2) Define forward on embeddings\n",
        "def forward_emb(inputs_embeds, attention_mask):\n",
        "    logits = model(inputs_embeds=inputs_embeds, attention_mask=attention_mask).logits\n",
        "    return logits  # return full [1, num_labels] for Occlusion to index\n",
        "\n",
        "occlusion = Occlusion(forward_emb)\n",
        "\n",
        "def occlusion_attributions(text, window_size=1):\n",
        "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    input_ids      = enc[\"input_ids\"]\n",
        "    attention_mask = enc[\"attention_mask\"]\n",
        "    embeds = model.get_input_embeddings()(input_ids)\n",
        "\n",
        "    # predicted class\n",
        "    with torch.no_grad():\n",
        "        logits = model(**enc).logits\n",
        "    target = int(logits.argmax(dim=-1).item())\n",
        "\n",
        "    # compute occlusion\n",
        "    seq_len, emb_dim = embeds.shape[1], embeds.shape[2]\n",
        "    atts = occlusion.attribute(\n",
        "        inputs=embeds,\n",
        "        target=target,\n",
        "        additional_forward_args=(attention_mask,),\n",
        "        sliding_window_shapes=(1, emb_dim),\n",
        "        strides=(1, emb_dim),\n",
        "    )  # [1, seq_len, emb_dim]\n",
        "\n",
        "    impacts = atts.squeeze(0).sum(dim=-1).cpu().numpy()\n",
        "    tokens  = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
        "    return tokens, impacts, target\n",
        "\n",
        "# 3) Load your dataset and pick an utterance\n",
        "df = pd.read_csv(\"/content/train_sent_emo_cleaned_processed.csv\", encoding=\"utf-8\")\n",
        "example_idx = 0  # change to any row you like\n",
        "text = df[\"Utterance\"].iloc[example_idx]\n",
        "\n",
        "print(f\"Utterance #{example_idx} (True: {df['Emotion'].iloc[example_idx]}):\\n{text}\\n\")\n",
        "\n",
        "# 4) Run Occlusion\n",
        "tokens, impacts, target = occlusion_attributions(text, window_size=1)\n",
        "\n",
        "print(\"Predicted class index:\", target)\n",
        "for tok, imp in zip(tokens, impacts):\n",
        "    print(f\"{tok:>8} → {imp:.2f}\")\n",
        "\n",
        "# 5) Plot\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.bar(tokens, impacts, color=\"salmon\", edgecolor=\"k\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"Occlusion Impact\")\n",
        "plt.title(f\"Occlusion Attribution per Token (idx={example_idx})\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTNGPv5WqrND"
      },
      "outputs": [],
      "source": [
        "# 0) Install if needed:\n",
        "# !pip install captum transformers torch pandas numpy matplotlib ipywidgets\n",
        "\n",
        "import torch, torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# 1) Load model & tokenizer\n",
        "MODEL_NAME = \"tae898/emoberta-base\"\n",
        "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model     = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(device).eval()\n",
        "\n",
        "# 2) Prediction helper\n",
        "def predict_probs(text):\n",
        "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    logits = model(**enc).logits\n",
        "    probs = F.softmax(logits, dim=-1).squeeze(0).cpu().detach().numpy()\n",
        "    return probs, enc\n",
        "\n",
        "# 3) The interactive function\n",
        "def explain_ngram(utt_idx, start, length):\n",
        "    clear_output(wait=True)\n",
        "    text = df[\"Utterance\"].iloc[utt_idx]\n",
        "    true = df[\"Emotion\"].iloc[utt_idx]\n",
        "    # original prediction\n",
        "    orig_probs, enc = predict_probs(text)\n",
        "    orig_label = model.config.id2label[int(orig_probs.argmax())]\n",
        "    orig_p     = orig_probs.max()\n",
        "    # tokenize once\n",
        "    toks = tokenizer.convert_ids_to_tokens(enc[\"input_ids\"].squeeze().tolist())\n",
        "    # display text + orig pred\n",
        "    display(HTML(f\"<b>Utterance #{utt_idx}</b> (True: <i>{true}</i>)<br/>{text}\"))\n",
        "    display(HTML(f\"<b>Original prediction:</b> {orig_label} (p={orig_p:.3f})\"))\n",
        "    # mask the selected n-gram\n",
        "    toks_masked = toks.copy()\n",
        "    for i in range(start, min(start+length, len(toks_masked))):\n",
        "        if toks_masked[i] not in tokenizer.all_special_tokens:\n",
        "            toks_masked[i] = tokenizer.mask_token\n",
        "    masked_text = tokenizer.convert_tokens_to_string(toks_masked)\n",
        "    # new prediction\n",
        "    new_probs, _ = predict_probs(masked_text)\n",
        "    new_label = model.config.id2label[int(new_probs.argmax())]\n",
        "    new_p     = new_probs.max()\n",
        "    # display masked text + new pred\n",
        "    display(HTML(f\"<b>Masked n-gram:</b> tokens[{start}:{start+length}] → {toks[start:start+length]}\"))\n",
        "    display(HTML(f\"<b>Masked text:</b> {masked_text}\"))\n",
        "    display(HTML(f\"<b>New prediction:</b> {new_label} (p={new_p:.3f})\"))\n",
        "    display(HTML(f\"<b>Δ in prob of orig label:</b> {orig_p - new_p:+.3f}\"))\n",
        "\n",
        "# 4) Load your data\n",
        "df = pd.read_csv(\"train_sent_emo_cleaned_processed.csv\", encoding=\"utf-8\")\n",
        "\n",
        "# 5) Build widgets\n",
        "utt_slider = widgets.IntSlider(\n",
        "    value=0, min=0, max=len(df)-1, step=1, description=\"Utterance\"\n",
        ")\n",
        "# we need to know max token length for the current utt:\n",
        "def update_max_len(*_):\n",
        "    toks = tokenizer.convert_ids_to_tokens(\n",
        "        tokenizer(df[\"Utterance\"].iloc[utt_slider.value],\n",
        "                  return_tensors=\"pt\", truncation=True, padding=True\n",
        "        )[\"input_ids\"].squeeze().tolist()\n",
        "    )\n",
        "    start_slider.max = len(toks)-1\n",
        "    length_slider.max = len(toks)\n",
        "\n",
        "utt_slider.observe(update_max_len, names=\"value\")\n",
        "\n",
        "start_slider = widgets.IntSlider(value=1, min=1, max=50, step=1, description=\"Start idx\")\n",
        "length_slider = widgets.IntSlider(value=1, min=1, max=50, step=1, description=\"N-gram length\")\n",
        "\n",
        "update_max_len()\n",
        "\n",
        "ui = widgets.VBox([utt_slider, start_slider, length_slider])\n",
        "out = widgets.interactive_output(\n",
        "    explain_ngram,\n",
        "    {\"utt_idx\": utt_slider, \"start\": start_slider, \"length\": length_slider}\n",
        ")\n",
        "\n",
        "display(ui, out)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07ae3da755c749f98f821e7add16987d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af8bdb3547d2496f9e51ab4446068fb4",
              "IPY_MODEL_7f75fb32d5ca4326b0ed7a195944c494",
              "IPY_MODEL_24d8212fbbdc49bba994151c44f7b979"
            ],
            "layout": "IPY_MODEL_7abcb6a99dfe4d548a0dd2d0ed4bddae"
          }
        },
        "af8bdb3547d2496f9e51ab4446068fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a4e1ab553844473ac255e69191577f4",
            "placeholder": "​",
            "style": "IPY_MODEL_431526763a9041e3b1255c0c5a61b553",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7f75fb32d5ca4326b0ed7a195944c494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6e9d529b6d943a198a9088f7b9ff6ea",
            "max": 407,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26aee59a512d454fb8c22bc78d6b3389",
            "value": 407
          }
        },
        "24d8212fbbdc49bba994151c44f7b979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e5b233326094e95b7fcdc207bf70124",
            "placeholder": "​",
            "style": "IPY_MODEL_59c24bbff9d54aa2a7fd13a4931a92ed",
            "value": " 407/407 [00:00&lt;00:00, 50.1kB/s]"
          }
        },
        "7abcb6a99dfe4d548a0dd2d0ed4bddae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a4e1ab553844473ac255e69191577f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "431526763a9041e3b1255c0c5a61b553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6e9d529b6d943a198a9088f7b9ff6ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26aee59a512d454fb8c22bc78d6b3389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e5b233326094e95b7fcdc207bf70124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c24bbff9d54aa2a7fd13a4931a92ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a312a1b9f7564fe9a69af0f4e3aeef12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb20727feab244eebf07bdc359fb92f3",
              "IPY_MODEL_91e1b8df0dec4ce28629edd2d1508378",
              "IPY_MODEL_3abef1ab0eab4c62ba49b2844688136f"
            ],
            "layout": "IPY_MODEL_5bd34c412dc246c6b6d8ab879feeb933"
          }
        },
        "bb20727feab244eebf07bdc359fb92f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3af99932bad49c8a93857f1d0aef96f",
            "placeholder": "​",
            "style": "IPY_MODEL_20ba4fb7895b4c959d2513d0324de64a",
            "value": "tokenizer.json: "
          }
        },
        "91e1b8df0dec4ce28629edd2d1508378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a10fb516a23643889c0d269399b4d87a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b61018d938a4fc891a2ae0397cd38d7",
            "value": 1
          }
        },
        "3abef1ab0eab4c62ba49b2844688136f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d48efb65a4c84ad1a274cb14ebf9980d",
            "placeholder": "​",
            "style": "IPY_MODEL_35c0926d72f6416486a4af203e630616",
            "value": " 2.11M/? [00:00&lt;00:00, 43.4MB/s]"
          }
        },
        "5bd34c412dc246c6b6d8ab879feeb933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3af99932bad49c8a93857f1d0aef96f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20ba4fb7895b4c959d2513d0324de64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a10fb516a23643889c0d269399b4d87a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1b61018d938a4fc891a2ae0397cd38d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d48efb65a4c84ad1a274cb14ebf9980d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35c0926d72f6416486a4af203e630616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b0761ad2caa46eb863acb1f7996c0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70689b99b371426ebf294a3d7f87aee1",
              "IPY_MODEL_bdd319f8d652420290dda79edd7eab88",
              "IPY_MODEL_bf01820ddf1848239e27363a06eb23d1"
            ],
            "layout": "IPY_MODEL_9f4e6f358f574b179506b2ec0364c75f"
          }
        },
        "70689b99b371426ebf294a3d7f87aee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba5d77aef59a43cf8bc9bb7f7ef41c1a",
            "placeholder": "​",
            "style": "IPY_MODEL_3b205a11f9414ecaad52557490f7348b",
            "value": "config.json: "
          }
        },
        "bdd319f8d652420290dda79edd7eab88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f508a5ed9a42cd8dbf4d175973f98a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afe70e4c263e4b318bc155f5eadca26a",
            "value": 1
          }
        },
        "bf01820ddf1848239e27363a06eb23d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6af22a9660ec43ad803fbfa9b3c3a698",
            "placeholder": "​",
            "style": "IPY_MODEL_c8bd34cd73054cffa4ca4ea31364936a",
            "value": " 1.02k/? [00:00&lt;00:00, 114kB/s]"
          }
        },
        "9f4e6f358f574b179506b2ec0364c75f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba5d77aef59a43cf8bc9bb7f7ef41c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b205a11f9414ecaad52557490f7348b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07f508a5ed9a42cd8dbf4d175973f98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "afe70e4c263e4b318bc155f5eadca26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6af22a9660ec43ad803fbfa9b3c3a698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8bd34cd73054cffa4ca4ea31364936a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0487fda4651475988cdca9a4b61aed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d9e05c866c24c7aaa303a61e294e998",
              "IPY_MODEL_dd2e166cfe84491896dd204ad129c708",
              "IPY_MODEL_81d139ac38d04fd1a976808360ee17b4"
            ],
            "layout": "IPY_MODEL_558829597bf341f5a183e67088721cf9"
          }
        },
        "0d9e05c866c24c7aaa303a61e294e998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_794cdd6f93af41128b6321d823f4e188",
            "placeholder": "​",
            "style": "IPY_MODEL_548faa36a4a84c13b0b88033ad5b35a8",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "dd2e166cfe84491896dd204ad129c708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3ee69ed0d1c42478233bd1975d52ee4",
            "max": 498686637,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_996ba88a2ddd4be7b10f373fc5954de6",
            "value": 498686637
          }
        },
        "81d139ac38d04fd1a976808360ee17b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b930c7814fa416c9e649d1a1bf7a277",
            "placeholder": "​",
            "style": "IPY_MODEL_e44e8e22561a442dba3a2c67bad4931a",
            "value": " 499M/499M [00:03&lt;00:00, 159MB/s]"
          }
        },
        "558829597bf341f5a183e67088721cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "794cdd6f93af41128b6321d823f4e188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "548faa36a4a84c13b0b88033ad5b35a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3ee69ed0d1c42478233bd1975d52ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "996ba88a2ddd4be7b10f373fc5954de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b930c7814fa416c9e649d1a1bf7a277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e44e8e22561a442dba3a2c67bad4931a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fdc6ad8926c451ca93231e3c051b753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_313effa8d28746ee8adc12d05a05e658",
              "IPY_MODEL_7930f6cb68634da1a992dd8433feef43",
              "IPY_MODEL_e8aff838f262450b85fe408be5482226"
            ],
            "layout": "IPY_MODEL_2cfbaf63157a488db596a6d2760fb0b4"
          }
        },
        "313effa8d28746ee8adc12d05a05e658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f40766baea764001b72cbb1e4c0f74d0",
            "placeholder": "​",
            "style": "IPY_MODEL_8e97d3f8a3ae41918b1dc34fbdbfec6b",
            "value": "model.safetensors: 100%"
          }
        },
        "7930f6cb68634da1a992dd8433feef43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_675044b42d1a4b4d8ea01f1263dedd10",
            "max": 498632404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_946614f365c447cd9c3f3e6ed8e31db6",
            "value": 498632404
          }
        },
        "e8aff838f262450b85fe408be5482226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c9eb588e2fb4106a8224fae9ae4d1a9",
            "placeholder": "​",
            "style": "IPY_MODEL_f4810b9434284606858e17196dbb31f9",
            "value": " 499M/499M [00:03&lt;00:00, 146MB/s]"
          }
        },
        "2cfbaf63157a488db596a6d2760fb0b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f40766baea764001b72cbb1e4c0f74d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e97d3f8a3ae41918b1dc34fbdbfec6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "675044b42d1a4b4d8ea01f1263dedd10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "946614f365c447cd9c3f3e6ed8e31db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c9eb588e2fb4106a8224fae9ae4d1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4810b9434284606858e17196dbb31f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}