{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryc4M--EayNv",
        "outputId": "47943be0-fb0b-4e26-fdd7-9047d8db4a0c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "!pip install torch-geometric\n",
        "!pip install numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4vrXK2NPgxl",
        "outputId": "8cb951d5-b743-4b5b-8c34-69c02fb20440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT5jTaJ2L-YA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "# 1. Load your pickled dataset\n",
        "df_train = pd.read_pickle('/content/drive/MyDrive/MELD/train_with_emb.pkl')\n",
        "df_dev = pd.read_pickle('/content/drive/MyDrive/MELD/dev_with_emb.pkl')\n",
        "df_test = pd.read_pickle('/content/drive/MyDrive/MELD/test_with_emb.pkl')\n",
        "\n",
        "# 2. Define a sentiment → ID helper\n",
        "_SENT2ID = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "def map_sentiments_to_ids(sentiments):\n",
        "    return [_SENT2ID[s] for s in sentiments]\n",
        "\n",
        "# 3. Build edges + sentiment‐shift attributes\n",
        "def compute_sentiment_edge_features(sent_ids):\n",
        "    src, dst, attr = [], [], []\n",
        "    L = len(sent_ids)\n",
        "    for i in range(L):\n",
        "        if i > 0:\n",
        "            src.append(i); dst.append(i-1)\n",
        "            attr.append([sent_ids[i], sent_ids[i-1]])\n",
        "        if i < L-1:\n",
        "            src.append(i); dst.append(i+1)\n",
        "            attr.append([sent_ids[i], sent_ids[i+1]])\n",
        "    # self-loops\n",
        "    for i in range(L):\n",
        "        src.append(i); dst.append(i)\n",
        "        attr.append([sent_ids[i], sent_ids[i]])\n",
        "    edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
        "    edge_attr  = torch.tensor(attr, dtype=torch.long)\n",
        "    return edge_index, edge_attr\n",
        "\n",
        "# 4. Function to build one graph\n",
        "def build_linecongat_graph(emb_list, sentiments, emotion_ids=None):\n",
        "    \"\"\"\n",
        "    emb_list     : list of np.ndarray, each shape (768,) for one utterance\n",
        "    sentiments   : list of strings of length L, each 'negative'/'neutral'/'positive'\n",
        "    emotion_ids  : optional list of int labels length L\n",
        "\n",
        "    Returns a torch_geometric.data.Data with:\n",
        "      - x                : [L, 768] node features\n",
        "      - edge_index       : [2, E] directed edges (i→i-1, i→i+1, i→i)\n",
        "      - edge_attr        : [E, 2] sentiment IDs [s_i, s_j]\n",
        "      - sentiment_shift  : [E] = s_j – s_i for each edge\n",
        "      - y (if provided)  : [L] node‐level emotion labels\n",
        "    \"\"\"\n",
        "    x = torch.from_numpy(np.stack(emb_list)).float()  # [L, 768]\n",
        "    sent_ids = map_sentiments_to_ids(sentiments)\n",
        "    edge_index, edge_attr = compute_sentiment_edge_features(sent_ids)\n",
        "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "    data.sentiment_shift = data.edge_attr[:, 1] - data.edge_attr[:, 0]\n",
        "    if emotion_ids is not None:\n",
        "        data.y = torch.tensor(emotion_ids, dtype=torch.long)\n",
        "    return data\n",
        "\n",
        "# 5. Define an emotion → index map for labels\n",
        "label2idx = {\n",
        "    'neutral': 0, 'surprise': 1, 'joy': 2, 'sadness': 3,\n",
        "    'anger': 4, 'fear': 5, 'disgust': 6, 'other': 7\n",
        "}\n",
        "\n",
        "# 6. Iterate over conversations\n",
        "graphs_train = []\n",
        "for dlg_id, grp in df_train.groupby('dialogue_id', sort=True):\n",
        "    grp = grp.sort_values('utterance_id')\n",
        "    emb_list   = grp['emb_array'].tolist()\n",
        "    sentiments = grp['sentiment_label'].tolist()\n",
        "    emos_int   = [label2idx[e] for e in grp['label'].tolist()]\n",
        "    g = build_linecongat_graph(emb_list, sentiments, emos_int)\n",
        "    graphs_train.append(g)\n",
        "\n",
        "# 7. (Optional) wrap in a DataLoader for batching\n",
        "train_loader = DataLoader(graphs_train, batch_size=16, shuffle=True)\n",
        "\n",
        "print(f\"Built {len(graphs_train)} graphs – example graph has {graphs_train[0].num_nodes} nodes.\")\n",
        "\n",
        "graphs_dev = []\n",
        "for dlg_id, grp in df_dev.groupby('dialogue_id', sort=True):\n",
        "    grp = grp.sort_values('utterance_id')\n",
        "    emb_list   = grp['emb_array'].tolist()\n",
        "    sentiments = grp['sentiment_label'].tolist()\n",
        "    emos_int   = [label2idx[e] for e in grp['label'].tolist()]\n",
        "    g_dev = build_linecongat_graph(emb_list, sentiments, emos_int)\n",
        "    graphs_dev.append(g_dev)\n",
        "\n",
        "# 7. (Optional) wrap in a DataLoader for batching\n",
        "dev_loader = DataLoader(graphs_dev, batch_size=16, shuffle=True)\n",
        "\n",
        "print(f\"Built {len(graphs_dev)} graphs – example graph has {graphs_dev[0].num_nodes} nodes.\")\n",
        "\n",
        "graphs_test = []\n",
        "for dlg_id, grp in df_test.groupby('dialogue_id', sort=True):\n",
        "    grp = grp.sort_values('utterance_id')\n",
        "    emb_list   = grp['emb_array'].tolist()\n",
        "    sentiments = grp['sentiment_label'].tolist()\n",
        "    emos_int   = [label2idx[e] for e in grp['label'].tolist()]\n",
        "    g_test = build_linecongat_graph(emb_list, sentiments, emos_int)\n",
        "    graphs_test.append(g_test)\n",
        "\n",
        "# 7. (Optional) wrap in a DataLoader for batching\n",
        "test_loader = DataLoader(graphs_test, batch_size=16, shuffle=True)\n",
        "\n",
        "print(f\"Built {len(graphs_test)} graphs – example graph has {graphs_test[0].num_nodes} nodes.\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pick one conversation to inspect, e.g. the very first\n",
        "g = graphs_test[0]\n",
        "\n",
        "# 1) Basic sizes\n",
        "print(\"Num utterances (nodes):\", g.num_nodes)\n",
        "print(\"Num edges (including self-loops):\", g.num_edges)\n",
        "print(\"Node-feature shape (L, d):\", g.x.shape)\n",
        "print(\"Edge-attr shape (E, 2):\", g.edge_attr.shape)\n",
        "print(\"Labels shape (L,):\", g.y.shape if hasattr(g, 'y') else None)\n",
        "print()\n",
        "\n",
        "# 2) Print the first few node embeddings (CLS vectors)\n",
        "print(\"First 3 node embeddings:\")\n",
        "print(g.x[:3])\n",
        "print()\n",
        "\n",
        "# 3) Peek at the first 10 edges (src→dst) and their sentiment shifts\n",
        "ei, ea = g.edge_index, g.edge_attr\n",
        "print(\"First 10 edges (src→dst) with [sent_src, sent_dst]:\")\n",
        "for idx in range(min(10, ei.size(1))):\n",
        "    print(f\"  {ei[0,idx].item()} → {ei[1,idx].item()}  {ea[idx].tolist()}\")\n",
        "print()\n",
        "\n",
        "# 4) Verify for each node i that it has edges to i−1, i, i+1\n",
        "print(\"Neighbors and sentiment shifts for each node:\")\n",
        "for i in range(g.num_nodes):\n",
        "    mask = (ei[0] == i)\n",
        "    nbrs     = ei[1, mask].tolist()\n",
        "    shifts   = ea[mask].tolist()\n",
        "    print(f\"  Node {i:2d}:  → {nbrs}  shifts={shifts}\")\n",
        "\n",
        "# 5) Finally, print the ground-truth labels for these utterances\n",
        "print(\"\\nEmotion labels (as ints):\", g.y.tolist())\n"
      ],
      "metadata": {
        "id": "hujVefFuT9aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GATv2Conv"
      ],
      "metadata": {
        "id": "gQ5mFwGe8zr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Model Definition\n",
        "class GATv2Layer(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, edge_dim=None, heads=6, concat=True,\n",
        "                 negative_slope=0.2, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.conv = GATv2Conv(\n",
        "            in_channels=in_dim, out_channels=out_dim,\n",
        "            heads=heads, concat=concat,\n",
        "            negative_slope=negative_slope, dropout=dropout,\n",
        "            edge_dim=edge_dim\n",
        "        )\n",
        "        self.act = nn.ELU() if concat else nn.Identity()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr=None):\n",
        "        out = self.conv(x, edge_index, edge_attr)\n",
        "        return self.act(out)\n",
        "\n",
        "class LineConGAT(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes,\n",
        "                 edge_dim=2, heads=6, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.layer0 = GATv2Layer(in_dim, hidden_dim, edge_dim, heads, True, 0.2, dropout)\n",
        "        self.layer1 = GATv2Layer(hidden_dim * heads, num_classes, edge_dim, heads, False, 0.2, dropout)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr,batch=None):\n",
        "        h = self.layer0(x, edge_index, edge_attr)\n",
        "        h = F.relu(h)\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "        logits = self.layer1(h, edge_index, edge_attr)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "4qP7odq78wt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Instantiate Model & Optimizer\n",
        "model = LineConGAT(\n",
        "    in_dim=768, hidden_dim=128, num_classes=len(label2idx),\n",
        "    edge_dim=2, heads=6, dropout=0.5\n",
        ")\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-3,        # learning rate 10^-3\n",
        "    weight_decay=1e-4  # L2 regularization 10^-4\n",
        ")\n",
        "print(model)"
      ],
      "metadata": {
        "id": "l7oma4mG84JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Training Loop\n",
        "num_epochs = 20\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "        loss = F.cross_entropy(logits, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch}/{num_epochs} — Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "Urx_JrZ789NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Evaluation Function and Run\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch\n",
        "            logits = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "            preds = logits.argmax(dim=1).cpu().tolist()\n",
        "            labels = batch.y.cpu().tolist()\n",
        "            all_preds.extend(preds); all_labels.extend(labels)\n",
        "    return accuracy_score(all_labels, all_preds), f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "train_acc, train_f1 = evaluate(train_loader)\n",
        "dev_acc, dev_f1     = evaluate(dev_loader)\n",
        "test_acc, test_f1   = evaluate(test_loader)\n",
        "print(f\"Train — Acc: {train_acc:.4f}, WA-F1: {train_f1:.4f}\")\n",
        "print(f\"Dev   — Acc: {dev_acc:.4f}, WA-F1: {dev_f1:.4f}\")\n",
        "print(f\"Test  — Acc: {test_acc:.4f}, WA-F1: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "0790QLit9Ee7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# — Configuration —\n",
        "graph_idx   = 0    # which dialogue-graph in train_graphs to inspect\n",
        "target_node = 3    # which node (utterance index) to trace attention from\n",
        "\n",
        "# 1) Select graph and move to device\n",
        "data = graphs_train[graph_idx]\n",
        "\n",
        "# 2) First-layer hidden reps\n",
        "h = model.layer0(data.x, data.edge_index, data.edge_attr)\n",
        "h = torch.relu(h)\n",
        "\n",
        "# 3) Second-layer attention\n",
        "_, (edge_index_clf, attn_weights) = model.layer1.conv(\n",
        "    h, data.edge_index, data.edge_attr, return_attention_weights=True\n",
        ")\n",
        "\n",
        "# 4) Collapse heads → one score per edge\n",
        "attn = attn_weights.mean(dim=1).cpu().detach()\n",
        "\n",
        "# 5) Build per-node attention from target_node\n",
        "N = data.num_nodes\n",
        "node_attn = torch.zeros(N)\n",
        "for eid, src in enumerate(edge_index_clf[0].cpu()):\n",
        "    if src.item() == target_node:\n",
        "        tgt = edge_index_clf[1, eid].item()\n",
        "        node_attn[tgt] = attn[eid].item()\n",
        "\n",
        "# 6) Plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(range(N), node_attn.numpy())\n",
        "plt.xlabel(\"Utterance (node) index\")\n",
        "plt.ylabel(f\"Attention weight from node {target_node}\")\n",
        "plt.title(f\"Graph {graph_idx}: attention from node {target_node}\")\n",
        "plt.xticks(range(N))\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hwD17n1dx8Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention_heatmap_layer1(model, data):\n",
        "    model.eval()\n",
        "    data = data\n",
        "    # Πρώτα φτιάχνουμε το h μετά τη layer0\n",
        "    h = model.layer0(data.x, data.edge_index, data.edge_attr)\n",
        "    h = F.relu(h)\n",
        "    # Παίρνουμε attention weights από layer1\n",
        "    _, (edge_idx, attn) = model.layer1.conv(\n",
        "        h, data.edge_index, data.edge_attr, return_attention_weights=True\n",
        "    )\n",
        "    # Detach the tensor before converting to numpy\n",
        "    attn = attn.mean(dim=1).cpu().detach().numpy()      # collapse heads\n",
        "    edge_idx = edge_idx.cpu().numpy()\n",
        "    N = data.num_nodes\n",
        "    mat = np.zeros((N, N))\n",
        "    for s, t, w in zip(edge_idx[0], edge_idx[1], attn):\n",
        "        mat[s, t] = w\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(mat, cmap='hot', interpolation='nearest')\n",
        "    plt.colorbar()\n",
        "    plt.title(\"Layer1 Attention Heatmap\")\n",
        "    plt.xlabel(\"Target node\")\n",
        "    plt.ylabel(\"Source node\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "kmCI1WXC6PI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_attention_heatmap_layer1(model, graphs_train[0])\n"
      ],
      "metadata": {
        "id": "EbjPQ0g-E2SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class GuidedBackprop:\n",
        "    def __init__(self, model):\n",
        "        \"\"\"\n",
        "        Αντιγράψτε το μοντέλο και αντικαταστήστε κάθε ReLU με ένα\n",
        "        όπου κατά το backward κρατάμε μόνο τα θετικά gradients.\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.handles = []\n",
        "        self._register_hooks()\n",
        "\n",
        "    def _register_hooks(self):\n",
        "        # Κάθε ReLU θα φιλτράρει τα αρνητικά gradients\n",
        "        for module in self.model.modules():\n",
        "            if isinstance(module, torch.nn.ReLU):\n",
        "                h = module.register_backward_hook(self._relu_backward_hook)\n",
        "                self.handles.append(h)\n",
        "\n",
        "    def _relu_backward_hook(self, module, grad_in, grad_out):\n",
        "        # Για κάθε είσοδο gradient grad_in[i], κρατάμε μόνο το θετικό μέρος:\n",
        "        modified = []\n",
        "        for g in grad_in:\n",
        "            if g is None:\n",
        "                modified.append(None)\n",
        "            else:\n",
        "                modified.append(F.relu(g))\n",
        "        return tuple(modified)\n",
        "\n",
        "    def generate_gradients(self, data, target_node, target_class):\n",
        "        \"\"\"\n",
        "        Εκτελεί forward/backward και επιστρέφει το gradient του data.x\n",
        "        Args:\n",
        "          data         : ένα torch_geometric.data.Data graph\n",
        "          target_node  : ο κόμβος που εξηγούμε (index)\n",
        "          target_class : η κλάση (π.χ. argmax) για την οποία κάνουμε backprop\n",
        "        Returns:\n",
        "          node_grads   : Tensor [N, d] με τα guided gradients w.r.t. x\n",
        "        \"\"\"\n",
        "        # 1) Σιγουρευόμαστε ότι το x έχει requires_grad\n",
        "        data = data\n",
        "        data.x = data.x.clone().detach().requires_grad_(True)\n",
        "\n",
        "        # 2) Forward\n",
        "        logits = self.model(data.x, data.edge_index, data.edge_attr)\n",
        "        score  = logits[target_node, target_class]\n",
        "\n",
        "        # 3) Backward guided\n",
        "        self.model.zero_grad()\n",
        "        score.backward(retain_graph=False)\n",
        "\n",
        "        # 4) Πάρτε τα gradients w.r.t. x\n",
        "        node_grads = data.x.grad.detach().cpu()  # [N, 768]\n",
        "        return node_grads\n",
        "\n",
        "    def clear_hooks(self):\n",
        "        for h in self.handles:\n",
        "            h.remove()\n",
        "        self.handles = []\n",
        "\n",
        "# —————— Παράδειγμα χρήσης ——————\n",
        "# 1) Δημιουργούμε instance του GuidedBackprop\n",
        "gb = GuidedBackprop(model)\n",
        "\n",
        "# 2) Παίρνουμε ένα graph και βρίσκουμε το predicted class για έναν κόμβο\n",
        "data = graphs_train[0]\n",
        "with torch.no_grad():\n",
        "    logits = model(data.x, data.edge_index, data.edge_attr)\n",
        "preds = logits.argmax(dim=1).cpu()\n",
        "target_node  = 5\n",
        "target_class = preds[target_node].item()\n",
        "\n",
        "# 3) Υπολογίζουμε τα guided gradients\n",
        "node_grads = gb.generate_gradients(data, target_node, target_class)\n",
        "# node_grads[i] είναι το gradient vector 768-διάστατο για κάθε κομβο i\n",
        "\n",
        "# 4) Μετατρέπουμε σε node-importance π.χ. με L1-norm\n",
        "import numpy as np\n",
        "node_importance = node_grads.abs().sum(dim=1).numpy()  # [N]\n",
        "\n",
        "# 5) Plot bar chart\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(range(data.num_nodes), node_importance)\n",
        "plt.xlabel(\"Node (utterance) index\")\n",
        "plt.ylabel(\"Guided Backprop importance (L1 norm)\")\n",
        "plt.title(f\"Guided Backprop for node {target_node}, class {target_class}\")\n",
        "plt.show()\n",
        "\n",
        "# 6) Καθαρίζουμε hooks όταν τελειώσουμε\n",
        "gb.clear_hooks()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "KSVO62MbE8bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def guided_backprop_heatmap(model, data):\n",
        "    \"\"\"\n",
        "    Computes a heatmap H where H[i,j] is the guided backprop importance\n",
        "    of node j for the prediction of node i.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    data = data.to(device)\n",
        "\n",
        "    # Prepare guided backprop hooks\n",
        "    gb = GuidedBackprop(model)\n",
        "\n",
        "    # Get model predictions for each node\n",
        "    with torch.no_grad():\n",
        "        logits = model(data.x, data.edge_index, data.edge_attr)\n",
        "    preds = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "    N = data.num_nodes\n",
        "    heat = np.zeros((N, N), dtype=float)\n",
        "\n",
        "    # For each target node i\n",
        "    for i in range(N):\n",
        "        target_class = preds[i].item()\n",
        "        # Compute guided gradients: shape [N, feature_dim]\n",
        "        node_grads = gb.generate_gradients(data, i, target_class)\n",
        "        # Aggregate per-source node j via L1 norm\n",
        "        node_imp = node_grads.abs().sum(dim=1).numpy()  # [N]\n",
        "        heat[i] = node_imp\n",
        "\n",
        "    gb.clear_hooks()\n",
        "    return heat\n",
        "\n",
        "# Example usage:\n",
        "data = graphs_train[0]  # first dialogue graph\n",
        "heatmap = guided_backprop_heatmap(model, data)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(\n",
        "    heatmap,\n",
        "    xticklabels=range(data.num_nodes),\n",
        "    yticklabels=range(data.num_nodes),\n",
        "    cmap='viridis'\n",
        ")\n",
        "plt.xlabel(\"Contributing node j\")\n",
        "plt.ylabel(\"Target node i\")\n",
        "plt.title(\"Guided Backprop Importance Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3NGaJmgXYqB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.explain import Explainer, GNNExplainer\n",
        "\n",
        "# 1) Select a conversation graph and move to device\n",
        "data = graphs_train[0]  # first dialogue\n",
        "# Ensure data has x, edge_index, edge_attr, y if available\n",
        "\n",
        "# 2) Instantiate the Explainer for your LineConGAT model\n",
        "explainer = Explainer(\n",
        "    model=model,\n",
        "    algorithm=GNNExplainer(200),\n",
        "    explanation_type='model',\n",
        "    node_mask_type='attributes',\n",
        "    edge_mask_type='object',\n",
        "    model_config={\n",
        "        'mode': 'multiclass_classification',\n",
        "        'task_level': 'node',\n",
        "        'return_type': 'log_probs',   # explains the log-softmax outputs\n",
        "    },\n",
        ")\n",
        "\n",
        "# 3) Pick a node index to explain, e.g., the 6th utterance\n",
        "target_node = 5\n",
        "\n",
        "# 4) Generate the explanation\n",
        "explanation = explainer(\n",
        "    x=data.x,\n",
        "    edge_index=data.edge_index,\n",
        "    edge_attr=data.edge_attr,\n",
        "    index=target_node\n",
        ")\n",
        "\n",
        "# 5) Access the learned masks\n",
        "edge_importance = explanation.edge_mask    # Tensor of length E\n",
        "node_importance = explanation.node_mask    # Tensor of length num_node_features\n",
        "\n",
        "print(\"Edge mask:\", edge_importance)\n",
        "print(\"Node feature mask:\", node_importance)\n"
      ],
      "metadata": {
        "id": "4jmWjAr91GlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.explain import Explainer, GNNExplainer, ModelConfig\n",
        "\n",
        "# 1) Pick a conversation‐graph and a target utterance‐node\n",
        "data        = graphs_train[0]   # first dialogue\n",
        "target_node = 5                            # utterance\n",
        "\n",
        "# 2) Instantiate the new Explainer API with GNNExplainer\n",
        "explainer = Explainer(\n",
        "    model            = model,\n",
        "    algorithm        = GNNExplainer(epochs=200),\n",
        "    explanation_type = 'model',\n",
        "    node_mask_type   = 'attributes',           # learn a mask over nodes\n",
        "    edge_mask_type   = 'object',               # learn a mask over edges\n",
        "    model_config     = ModelConfig(\n",
        "                            mode='multiclass_classification',\n",
        "                            task_level='node',\n",
        "                            return_type='log_probs'\n",
        "                       ),\n",
        ")\n",
        "\n",
        "# 3) Run the explainer for your target node\n",
        "explanation = explainer(\n",
        "    x     = data.x,\n",
        "    edge_index = data.edge_index,\n",
        "    edge_attr  = data.edge_attr,\n",
        "    index = target_node\n",
        ")\n",
        "\n",
        "# 4) Print all outgoing edge‐importance from your target node\n",
        "# 4) Print all edge‐importance scores for the entire graph\n",
        "edge_idx  = data.edge_index.cpu().numpy()\n",
        "edge_mask = explanation.edge_mask.cpu().numpy()\n",
        "print(\"All edges and their learned importance:\")\n",
        "for src, tgt, w in zip(edge_idx[0], edge_idx[1], edge_mask):\n",
        "    print(f\"Node {src} → Node {tgt} : {w:.4f}\")\n",
        "\n",
        "\n",
        "explanation.visualize_graph(path=\"subgraph_visualization.png\")\n",
        "img = plt.imread(\"subgraph_visualization.png\")\n",
        "plt.imshow(img); plt.axis(\"off\"); plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "MPoqGS9P5upy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}