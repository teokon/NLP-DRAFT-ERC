{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "#import os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "import os, re\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D-3DLGN0QzU",
        "outputId": "bfc80737-3a81-41d5-b80f-e1c5f70a3476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5qyRgN7Pjum",
        "outputId": "7b24317c-9780-49eb-a1b5-cc3dbc095f4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✓ Saved → /content/drive/MyDrive/MELD/train_for_student_paragraph.csv  (rows: 9988)\n",
            "✓ Saved → /content/drive/MyDrive/MELD/dev_for_student_paragraph.csv  (rows: 1108)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ===== config =====\n",
        "BASE = \"/content/drive/MyDrive/MELD\"\n",
        "\n",
        "# teacher predictions (must contain at least Dialogue/Utterance/Speaker/Utterance + pred + conf)\n",
        "TEACH_TRAIN = os.path.join(BASE, \"teacher_predictions_train.csv\")\n",
        "TEACH_DEV   = os.path.join(BASE, \"teacher_predictions_dev.csv\")\n",
        "\n",
        "# raw MELD splits (contain gold Emotion)\n",
        "RAW_TRAIN   = os.path.join(BASE, \"train_with_context.csv\")\n",
        "RAW_DEV     = os.path.join(BASE, \"dev_with_context.csv\")\n",
        "\n",
        "# outputs\n",
        "OUT_TRAIN   = os.path.join(BASE, \"train_for_student_paragraph.csv\")\n",
        "OUT_DEV     = os.path.join(BASE, \"dev_for_student_paragraph.csv\")\n",
        "\n",
        "# suggestive text controls\n",
        "TAU = 0.70       # confidence threshold for inserting adverbs\n",
        "K_PAST = 2       # number of previous utterances to include\n",
        "K_FUT  = 2       # number of following utterances to include\n",
        "\n",
        "EMO_ADVERB = {\n",
        "    \"anger\":\"angrily\", \"disgust\":\"disgustedly\", \"fear\":\"fearfully\",\n",
        "    \"joy\":\"joyfully\", \"neutral\":\"neutrally\", \"sadness\":\"sadly\", \"surprise\":\"surprisingly\"\n",
        "}\n",
        "\n",
        "def pick_col(df, candidates):\n",
        "    cols = {c.lower(): c for c in df.columns}\n",
        "    for name in candidates:\n",
        "        if name in df.columns: return name\n",
        "        if name.lower() in cols: return cols[name.lower()]\n",
        "    raise KeyError(f\"Need one of {candidates}, have {list(df.columns)}\")\n",
        "\n",
        "def norm(s):  # compact whitespace\n",
        "    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
        "\n",
        "def format_context_line(spk, text, pred, conf):\n",
        "    \"\"\"Context: 'Speaker [adverb?] says: text' where adverb is used if conf≥TAU.\"\"\"\n",
        "    adv = EMO_ADVERB.get(str(pred)) if (pd.notna(conf) and float(conf) >= TAU) else None\n",
        "    if adv:\n",
        "        return f\"{spk} {adv} says: {text}\"\n",
        "    return f\"{spk} says: {text}\"\n",
        "\n",
        "def build_paragraph_rows(teach_csv, raw_csv, out_csv):\n",
        "    # load dfs\n",
        "    t = pd.read_csv(teach_csv)\n",
        "    r = pd.read_csv(raw_csv)\n",
        "\n",
        "    # teacher columns\n",
        "    T_DID   = pick_col(t, [\"Dialogue_ID\",\"conv_id\",\"Conversation_ID\",\"dialogue_id\"])\n",
        "    T_UID   = pick_col(t, [\"Utterance_ID\",\"utt_id\",\"Utterance_ID_in_Dialogue\",\"utterance_id\"])\n",
        "    T_SPK   = pick_col(t, [\"Speaker\",\"speaker\",\"speaker_id\"])\n",
        "    T_UTT   = pick_col(t, [\"Utterance\",\"utterance\",\"text\"])\n",
        "    T_PRED  = pick_col(t, [\"pred\",\"pred_label\",\"coarse_pred\",\"teacher_pred\"])\n",
        "    T_CONF  = pick_col(t, [\"conf\",\"pred_confidence\",\"coarse_conf\",\"teacher_confidence\"])\n",
        "\n",
        "    # raw columns (for gold label)\n",
        "    R_DID   = pick_col(r, [\"Dialogue_ID\",\"conv_id\",\"Conversation_ID\",\"dialogue_id\"])\n",
        "    R_UID   = pick_col(r, [\"Utterance_ID\",\"utt_id\",\"Utterance_ID_in_Dialogue\",\"utterance_id\"])\n",
        "    R_EMO   = pick_col(r, [\"Emotion\",\"emotion\",\"label\"])\n",
        "\n",
        "    # merge gold Emotion\n",
        "    df = t.merge(\n",
        "        r[[R_DID, R_UID, R_EMO]],\n",
        "        left_on=[T_DID, T_UID],\n",
        "        right_on=[R_DID, R_UID],\n",
        "        how=\"left\",\n",
        "        validate=\"one_to_one\",\n",
        "    ).rename(columns={\n",
        "        T_DID:\"DID\", T_UID:\"UID\", T_SPK:\"SPK\", T_UTT:\"UTT\",\n",
        "        T_PRED:\"PRED\", T_CONF:\"CONF\", R_EMO:\"EMO\"\n",
        "    })\n",
        "\n",
        "    # sort by dialogue order\n",
        "    df = df.sort_values([\"DID\",\"UID\"]).reset_index(drop=True)\n",
        "\n",
        "    # group by dialogue\n",
        "    paragraphs = []\n",
        "    for did, sub in df.groupby(\"DID\", sort=False):\n",
        "        sub = sub.sort_values(\"UID\").reset_index(drop=True)\n",
        "\n",
        "        # build a quick lookup by absolute index\n",
        "        for i in range(len(sub)):\n",
        "            # context window indices\n",
        "            left  = max(0, i - K_PAST)\n",
        "            right = min(len(sub), i + 1 + K_FUT)\n",
        "\n",
        "            pieces = []\n",
        "\n",
        "            # PAST\n",
        "            for j in range(left, i):\n",
        "                spk = str(sub.loc[j, \"SPK\"])\n",
        "                txt = norm(sub.loc[j, \"UTT\"])\n",
        "                prd = sub.loc[j, \"PRED\"]\n",
        "                cnf = sub.loc[j, \"CONF\"]\n",
        "                pieces.append(format_context_line(spk, txt, prd, cnf))\n",
        "\n",
        "            # QUERY (mask adverb; always exactly one masked line)\n",
        "            spk_q = str(sub.loc[i, \"SPK\"])\n",
        "            txt_q = norm(sub.loc[i, \"UTT\"])\n",
        "            # query line: '<s> Speaker <mask> says: text </s>'\n",
        "            pieces.append(f\"<s> {spk_q} <mask> says: {txt_q} </s>\")\n",
        "\n",
        "            # FUTURE\n",
        "            for j in range(i + 1, right):\n",
        "                spk = str(sub.loc[j, \"SPK\"])\n",
        "                txt = norm(sub.loc[j, \"UTT\"])\n",
        "                prd = sub.loc[j, \"PRED\"]\n",
        "                cnf = sub.loc[j, \"CONF\"]\n",
        "                pieces.append(format_context_line(spk, txt, prd, cnf))\n",
        "\n",
        "            paragraphs.append({\n",
        "                \"student_input\": \" \".join(pieces),\n",
        "                \"Emotion\": str(sub.loc[i, \"EMO\"])\n",
        "            })\n",
        "\n",
        "    out_df = pd.DataFrame(paragraphs)\n",
        "    out_df.to_csv(out_csv, index=False)\n",
        "    print(f\"✓ Saved → {out_csv}  (rows: {len(out_df)})\")\n",
        "\n",
        "# run for train + dev\n",
        "build_paragraph_rows(TEACH_TRAIN, RAW_TRAIN, OUT_TRAIN)\n",
        "build_paragraph_rows(TEACH_DEV,   RAW_DEV,   OUT_DEV)\n"
      ]
    }
  ]
}