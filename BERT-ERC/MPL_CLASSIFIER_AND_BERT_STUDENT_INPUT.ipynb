{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWD8dZ5Nz_L-",
        "outputId": "2c5cc2e1-daad-49d4-cd14-989665e7f65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bpYXOUgzNFw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from datasets import Dataset\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive (if needed)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ─── Paths & Globals ─────────────────────────────────────────────────────────\n",
        "base       = \"/content/drive/MyDrive/MELD\"\n",
        "checkpoint = os.path.join(base, \"teacher_roberta_erc\")    # your fine-tuned model\n",
        "outs_dir   = os.path.join(base, \"segment_embeddings\")\n",
        "os.makedirs(outs_dir, exist_ok=True)\n",
        "\n",
        "# ─── Device & Encoder ─────────────────────────────────────────────────────────\n",
        "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = AutoModel.from_pretrained(\n",
        "    checkpoint,\n",
        "    local_files_only=True   # ensure it loads from Drive, not Hub\n",
        ").to(device)\n",
        "encoder.eval()\n",
        "\n",
        "# ─── Tokenizer & Marker IDs ───────────────────────────────────────────────────\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "s_id  = tokenizer.convert_tokens_to_ids(\"<s>\")   # your inserted start marker\n",
        "es_id = tokenizer.convert_tokens_to_ids(\"</s>\")  # your inserted end marker\n",
        "\n",
        "# ─── Load the CSVs ─────────────────────────────────────────────────────────────\n",
        "dfs = {\n",
        "    split: pd.read_csv(f\"{base}/{split}_with_context.csv\")\n",
        "    for split in (\"train\", \"dev\", \"test\")\n",
        "}\n",
        "\n",
        "# ─── 1) Recompute query spans correctly ───────────────────────────────────────\n",
        "def find_span(text):\n",
        "    # Turn off default special tokens so we see only your markers\n",
        "    ids = tokenizer(\n",
        "        text,\n",
        "        add_special_tokens=False,\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )[\"input_ids\"]\n",
        "    try:\n",
        "        start = ids.index(s_id)\n",
        "        end   = ids.index(es_id, start+1)\n",
        "    except ValueError:\n",
        "        # if something’s wrong, mark invalid\n",
        "        start, end = -1, -1\n",
        "    return (start, end)\n",
        "\n",
        "for split, df in dfs.items():\n",
        "    df[\"query_span\"] = df[\"bert_input\"].apply(find_span)\n",
        "    # overwrite if you want\n",
        "    df.to_csv(f\"{base}/{split}_with_spans.csv\", index=False)\n",
        "    dfs[split] = df\n",
        "\n",
        "# ─── 2) Build DataLoader ──────────────────────────────────────────────────────\n",
        "def make_loader(df, batch_size=32):\n",
        "    ds = Dataset.from_pandas(df)\n",
        "    def collate(batch):\n",
        "        texts = [ex[\"bert_input\"] for ex in batch]\n",
        "        spans = torch.tensor([ex[\"query_span\"] for ex in batch], dtype=torch.long)\n",
        "        enc = tokenizer(\n",
        "            texts,\n",
        "            padding=\"longest\",\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            add_special_tokens=False,   # same here!\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return enc[\"input_ids\"], enc[\"attention_mask\"], spans\n",
        "    return DataLoader(ds, batch_size=batch_size, collate_fn=collate)\n",
        "\n",
        "loaders = {split: make_loader(df) for split, df in dfs.items()}\n",
        "\n",
        "# ─── 3) Inference Loop: extract & save Fp, Fq, Ff ─────────────────────────────\n",
        "for split, loader in loaders.items():\n",
        "    all_Fcls = []\n",
        "    all_Fp, all_Fq, all_Ff = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask, spans in loader:\n",
        "            input_ids      = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            spans          = spans.to(device)\n",
        "\n",
        "            hs = encoder(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            ).last_hidden_state  # [B, S, H]\n",
        "            B, S, H = hs.size()\n",
        "\n",
        "            Fp = torch.zeros((B, H), device=device)\n",
        "            Fq = torch.zeros((B, H), device=device)\n",
        "            Ff = torch.zeros((B, H), device=device)\n",
        "\n",
        "            for i, (a, b) in enumerate(spans.tolist()):\n",
        "                if a > 0:\n",
        "                    Fp[i] = hs[i, :a].mean(dim=0)\n",
        "                if b >= a:\n",
        "                    Fq[i] = hs[i, a : b+1].mean(dim=0)\n",
        "                if b+1 < S and b >= 0:\n",
        "                    Ff[i] = hs[i, b+1 :].mean(dim=0)\n",
        "\n",
        "            all_Fp.append(Fp.cpu())\n",
        "            all_Fq.append(Fq.cpu())\n",
        "            all_Ff.append(Ff.cpu())\n",
        "\n",
        "            Fcls = torch.cat([Fp, Fq, Ff], dim=1)  # [B, 3*H]\n",
        "            all_Fcls.append(Fcls.cpu())\n",
        "\n",
        "    Fp_tensor = torch.cat(all_Fp, dim=0)\n",
        "    Fq_tensor = torch.cat(all_Fq, dim=0)\n",
        "    Ff_tensor = torch.cat(all_Ff, dim=0)\n",
        "    Fcls_tensor = torch.cat(all_Fcls, dim=0)\n",
        "\n",
        "    torch.save(Fp_tensor, os.path.join(outs_dir, f\"{split}_Fp.pt\"))\n",
        "    torch.save(Fq_tensor, os.path.join(outs_dir, f\"{split}_Fq.pt\"))\n",
        "    torch.save(Ff_tensor, os.path.join(outs_dir, f\"{split}_Ff.pt\"))\n",
        "    torch.save(Fcls_tensor, os.path.join(outs_dir, f\"{split}_Fcls.pt\"))\n",
        "    print(f\"[{split}] saved Fcls shape:\", Fcls_tensor.shape)\n",
        "    print(f\"[{split}] saved shapes:\",\n",
        "          Fp_tensor.shape, Fq_tensor.shape, Ff_tensor.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 10 rows of the span column alongside the input text\n",
        "display(df.loc[:20, [\"bert_input\", \"query_span\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "kV66hP-vzidy",
        "outputId": "feaa22b2-1c14-4bd5-d19b-536dc170ea57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                           bert_input query_span\n",
              "0   <s> Mark <mask> says: Why do all you’re coffee...    (0, 22)\n",
              "1   <s> Rachel <mask> says: Oh. That’s so Monica c...    (0, 43)\n",
              "2   Rachel says: Oh. That’s so Monica can keep tra...   (40, 51)\n",
              "3   <s> Joey <mask> says: Come on, Lydia, you can ...    (0, 16)\n",
              "4   Joey says: Come on, Lydia, you can do it.<s> J...   (14, 22)\n",
              "5   Joey says: Push!<s> Joey <mask> says: Push 'em...    (6, 26)\n",
              "6   Joey says: Push 'em out, push 'em out, harder,...   (18, 37)\n",
              "7   Joey says: Push 'em out, push 'em out, way out...   (17, 40)\n",
              "8   Joey says: Let's get that ball and really move...   (21, 39)\n",
              "9   Joey says: Let's—  I was just—yeah, right.<s> ...   (16, 24)\n",
              "10   Joey says: Push!<s> Joey <mask> says: Push! </s>    (6, 14)\n",
              "11  <s> Ross <mask> says: Okay. </s>Ross says: Uhh...     (0, 8)\n",
              "12  <s> Rachel <mask> says: Ross, didn't you say t...    (0, 20)\n",
              "13  Ross says: Okay.<s> Ross <mask> says: Uhh, yes...    (5, 28)\n",
              "14  Ross says: Uhh, yes I did but there isn't. Oka...   (20, 35)\n",
              "15  Rachel says: Ross, didn't you say that there w...   (17, 38)\n",
              "16  Ross says: Okay, go left. Left! Left!<s> Ross ...   (12, 29)\n",
              "17  Ross says: Oh okay, lift it straight up over y...   (14, 26)\n",
              "18  Ross says: Straight up over your head!<s> Ross...    (9, 20)\n",
              "19  Ross says: You can do it!<s> Ross <mask> says:...    (8, 19)\n",
              "20  Ross says: You can do it!<s> Ross <mask> says:...    (8, 16)"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c269cc2d-e2f3-46d1-93b5-c74a6008b264\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bert_input</th>\n",
              "      <th>query_span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt; Mark &lt;mask&gt; says: Why do all you’re coffee...</td>\n",
              "      <td>(0, 22)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt; Rachel &lt;mask&gt; says: Oh. That’s so Monica c...</td>\n",
              "      <td>(0, 43)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rachel says: Oh. That’s so Monica can keep tra...</td>\n",
              "      <td>(40, 51)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt; Joey &lt;mask&gt; says: Come on, Lydia, you can ...</td>\n",
              "      <td>(0, 16)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Joey says: Come on, Lydia, you can do it.&lt;s&gt; J...</td>\n",
              "      <td>(14, 22)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Joey says: Push!&lt;s&gt; Joey &lt;mask&gt; says: Push 'em...</td>\n",
              "      <td>(6, 26)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Joey says: Push 'em out, push 'em out, harder,...</td>\n",
              "      <td>(18, 37)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Joey says: Push 'em out, push 'em out, way out...</td>\n",
              "      <td>(17, 40)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Joey says: Let's get that ball and really move...</td>\n",
              "      <td>(21, 39)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Joey says: Let's—  I was just—yeah, right.&lt;s&gt; ...</td>\n",
              "      <td>(16, 24)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Joey says: Push!&lt;s&gt; Joey &lt;mask&gt; says: Push! &lt;/s&gt;</td>\n",
              "      <td>(6, 14)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>&lt;s&gt; Ross &lt;mask&gt; says: Okay. &lt;/s&gt;Ross says: Uhh...</td>\n",
              "      <td>(0, 8)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>&lt;s&gt; Rachel &lt;mask&gt; says: Ross, didn't you say t...</td>\n",
              "      <td>(0, 20)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Ross says: Okay.&lt;s&gt; Ross &lt;mask&gt; says: Uhh, yes...</td>\n",
              "      <td>(5, 28)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ross says: Uhh, yes I did but there isn't. Oka...</td>\n",
              "      <td>(20, 35)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Rachel says: Ross, didn't you say that there w...</td>\n",
              "      <td>(17, 38)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Ross says: Okay, go left. Left! Left!&lt;s&gt; Ross ...</td>\n",
              "      <td>(12, 29)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Ross says: Oh okay, lift it straight up over y...</td>\n",
              "      <td>(14, 26)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Ross says: Straight up over your head!&lt;s&gt; Ross...</td>\n",
              "      <td>(9, 20)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Ross says: You can do it!&lt;s&gt; Ross &lt;mask&gt; says:...</td>\n",
              "      <td>(8, 19)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Ross says: You can do it!&lt;s&gt; Ross &lt;mask&gt; says:...</td>\n",
              "      <td>(8, 16)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c269cc2d-e2f3-46d1-93b5-c74a6008b264')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c269cc2d-e2f3-46d1-93b5-c74a6008b264 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c269cc2d-e2f3-46d1-93b5-c74a6008b264');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c37c3f82-7954-474e-b606-cb01d5bac892\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c37c3f82-7954-474e-b606-cb01d5bac892')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c37c3f82-7954-474e-b606-cb01d5bac892 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"bert_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"<s> Mark <mask> says: Why do all you\\u2019re coffee mugs have numbers on the bottom? </s>\",\n          \"Ross says: Oh okay, lift it straight up over your head!<s> Ross <mask> says: Straight up over your head! </s>Ross says: You can do it!\",\n          \"Rachel says: Ross, didn't you say that there was an elevator in here?<s> Rachel <mask> says: Okay, y'know what? There is no more left, left! </s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query_span\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          [\n            0,\n            22\n          ],\n          [\n            14,\n            26\n          ],\n          [\n            17,\n            38\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 1) Load your concatenated features tensor\n",
        "base = \"/content/drive/MyDrive/MELD/segment_embeddings\"\n",
        "Fcls_train = torch.load(f\"{base}/train_Fcls.pt\")  # [N, 3*H]\n",
        "Fcls_dev   = torch.load(f\"{base}/dev_Fcls.pt\")\n",
        "Fcls_test  = torch.load(f\"{base}/test_Fcls.pt\")\n",
        "\n",
        "# 2) Define the Fine-Grained MLP head exactly as used in training\n",
        "class FineGrainedHead(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, num_labels: int, dropout: float = 0.3):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.act = nn.Tanh()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_labels)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.act(self.fc1(x))  # FC + Tanh\n",
        "        x = self.drop(x)           # Dropout\n",
        "        logits = self.fc2(x)       # Final linear -> logits\n",
        "        return logits\n",
        "\n",
        "# 3) Instantiate and load any pretrained head weights if available\n",
        "hidden_size = 768\n",
        "input_dim   = 3 * hidden_size\n",
        "num_labels  = 7\n",
        "head = FineGrainedHead(input_dim, hidden_size, num_labels)\n",
        "\n",
        "# If you saved the head state_dict previously, load it:\n",
        "# head.load_state_dict(torch.load(\"/content/drive/MyDrive/MELD/head_weights.pt\"))\n",
        "\n",
        "head.eval()\n",
        "\n",
        "# 4) Compute probabilities for each split\n",
        "with torch.no_grad():\n",
        "    logits_train = head(Fcls_train)           # [N_train, num_labels]\n",
        "    probs_train  = F.softmax(logits_train, dim=1)   # [N_train, num_labels]\n",
        "\n",
        "    logits_dev = head(Fcls_dev)\n",
        "    probs_dev  = F.softmax(logits_dev, dim=1)\n",
        "\n",
        "    logits_test = head(Fcls_test)\n",
        "    probs_test  = F.softmax(logits_test, dim=1)\n",
        "\n",
        "# 5) Inspect shapes and a few sample probabilities\n",
        "print(\"Train probabilities shape:\", probs_train.shape)\n",
        "print(\"Sample train probabilities (first 5 rows):\")\n",
        "print(probs_train[:25])\n",
        "\n",
        "# 6) (Optional) Convert to NumPy and save for later use:\n",
        "probs_train_np = probs_train.cpu().numpy()\n",
        "torch.save(probs_train, f\"{base}/train_probs.pt\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qL9USFV-8RC",
        "outputId": "9046fe88-de81-4c29-e295-5a7ab27e99e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train probabilities shape: torch.Size([9988, 7])\n",
            "Sample train probabilities (first 5 rows):\n",
            "tensor([[0.1246, 0.1137, 0.1698, 0.1739, 0.1121, 0.1311, 0.1747],\n",
            "        [0.1090, 0.1288, 0.1657, 0.1701, 0.1105, 0.1356, 0.1804],\n",
            "        [0.1508, 0.0997, 0.1920, 0.1528, 0.1049, 0.1153, 0.1843],\n",
            "        [0.1132, 0.1250, 0.1912, 0.1698, 0.0939, 0.1135, 0.1932],\n",
            "        [0.1702, 0.1649, 0.1332, 0.1454, 0.0939, 0.1233, 0.1691],\n",
            "        [0.1379, 0.1199, 0.1685, 0.1637, 0.0903, 0.1247, 0.1952],\n",
            "        [0.1244, 0.1171, 0.1616, 0.1549, 0.1084, 0.1604, 0.1732],\n",
            "        [0.1251, 0.1129, 0.1754, 0.1414, 0.1071, 0.1418, 0.1962],\n",
            "        [0.1315, 0.1214, 0.1620, 0.1412, 0.1348, 0.1336, 0.1754],\n",
            "        [0.1408, 0.1283, 0.1605, 0.1478, 0.1127, 0.1279, 0.1821],\n",
            "        [0.1634, 0.1201, 0.1124, 0.1289, 0.1220, 0.1438, 0.2093],\n",
            "        [0.1345, 0.1072, 0.1934, 0.1429, 0.1142, 0.1278, 0.1800],\n",
            "        [0.1765, 0.1622, 0.1090, 0.1076, 0.1624, 0.1292, 0.1530],\n",
            "        [0.1188, 0.1011, 0.1967, 0.1446, 0.1149, 0.1363, 0.1877],\n",
            "        [0.1505, 0.1435, 0.1125, 0.1733, 0.1516, 0.1423, 0.1264],\n",
            "        [0.1408, 0.1146, 0.1261, 0.1815, 0.1289, 0.1493, 0.1587],\n",
            "        [0.1700, 0.1527, 0.1063, 0.1316, 0.1597, 0.1323, 0.1475],\n",
            "        [0.1547, 0.0851, 0.1172, 0.1192, 0.1293, 0.1235, 0.2710],\n",
            "        [0.1774, 0.1129, 0.1272, 0.1705, 0.1330, 0.1098, 0.1691],\n",
            "        [0.1055, 0.1060, 0.2004, 0.1560, 0.1270, 0.1219, 0.1831],\n",
            "        [0.1431, 0.0831, 0.1562, 0.1376, 0.1346, 0.1308, 0.2146],\n",
            "        [0.1016, 0.1266, 0.1828, 0.1587, 0.1295, 0.1454, 0.1554],\n",
            "        [0.1120, 0.1431, 0.1462, 0.1293, 0.1488, 0.1608, 0.1598],\n",
            "        [0.1534, 0.0896, 0.1189, 0.1420, 0.1709, 0.1166, 0.2087],\n",
            "        [0.1337, 0.1116, 0.1288, 0.1248, 0.1431, 0.1361, 0.2218]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "\n",
        "# ─── Configuration ────────────────────────────────────────────────────────────\n",
        "base = \"/content/drive/MyDrive/MELD\"\n",
        "features_dir = os.path.join(base, \"features\")\n",
        "head_save_path = os.path.join(base, \"head_finetuned.pt\")\n",
        "\n",
        "# Hyperparameters\n",
        "hidden_size = 768\n",
        "input_dim   = 3 * hidden_size\n",
        "num_labels  = 7\n",
        "dropout     = 0.3\n",
        "lr          = 1e-3\n",
        "batch_size  = 32\n",
        "epochs      = 10\n",
        "device      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ─── 1) Load Fcls features and labels ─────────────────────────────────────────\n",
        "# Features\n",
        "base1 = \"/content/drive/MyDrive/MELD/segment_embeddings\"\n",
        "Fcls_train = torch.load(f\"{base1}/train_Fcls.pt\")  # [N, 3*H]\n",
        "Fcls_dev   = torch.load(f\"{base1}/dev_Fcls.pt\")\n",
        "\n",
        "# Labels from CSV\n",
        "df_train = pd.read_csv(os.path.join(base, \"train_with_spans.csv\"))\n",
        "df_dev   = pd.read_csv(os.path.join(base, \"dev_with_spans.csv\"))\n",
        "\n",
        "# Map emotions to integer IDs\n",
        "EMOTIONS = [\"anger\",\"disgust\",\"fear\",\"joy\",\"neutral\",\"sadness\",\"surprise\"]\n",
        "label_map = {emo: i for i, emo in enumerate(EMOTIONS)}\n",
        "labels_train = torch.tensor(df_train[\"Emotion\"].map(label_map).values, dtype=torch.long)\n",
        "labels_dev   = torch.tensor(df_dev[\"Emotion\"].map(label_map).values, dtype=torch.long)\n",
        "\n",
        "# ─── 2) Create DataLoaders ────────────────────────────────────────────────────\n",
        "train_ds = TensorDataset(Fcls_train, labels_train)\n",
        "dev_ds   = TensorDataset(Fcls_dev,   labels_dev)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "dev_loader   = DataLoader(dev_ds,   batch_size=batch_size)\n",
        "\n",
        "# ─── 3) Define Fine-Grained MLP Head ──────────────────────────────────────────\n",
        "class FineGrainedHead(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_labels, dropout):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.act = nn.Tanh()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_labels)\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# Instantiate\n",
        "head = FineGrainedHead(input_dim, hidden_size, num_labels, dropout).to(device)\n",
        "\n",
        "# ─── 4) Training Setup ─────────────────────────────────────────────────────────\n",
        "optimizer = optim.AdamW(head.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ─── 5) Training Loop ─────────────────────────────────────────────────────────\n",
        "for epoch in range(1, epochs+1):\n",
        "    head.train()\n",
        "    total_loss = 0.0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = head(X_batch)\n",
        "        loss = criterion(logits, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * X_batch.size(0)\n",
        "    avg_train_loss = total_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Evaluate on dev\n",
        "    head.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in dev_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            logits = head(X_batch)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "    dev_acc = correct / total\n",
        "\n",
        "    print(f\"Epoch {epoch}/{epochs} • Train Loss: {avg_train_loss:.4f} • Dev Acc: {dev_acc:.4f}\")\n",
        "\n",
        "# ─── 6) Save the Fine-Tuned Head ───────────────────────────────────────────────\n",
        "torch.save(head.state_dict(), head_save_path)\n",
        "print(f\"Saved fine-tuned head weights to {head_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU1B7_ilCmwo",
        "outputId": "fa4260e6-3175-4f57-91de-c36a50eade8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 • Train Loss: 0.8883 • Dev Acc: 0.6101\n",
            "Epoch 2/10 • Train Loss: 0.8309 • Dev Acc: 0.6137\n",
            "Epoch 3/10 • Train Loss: 0.8056 • Dev Acc: 0.6083\n",
            "Epoch 4/10 • Train Loss: 0.8062 • Dev Acc: 0.6119\n",
            "Epoch 5/10 • Train Loss: 0.8019 • Dev Acc: 0.6191\n",
            "Epoch 6/10 • Train Loss: 0.7998 • Dev Acc: 0.6074\n",
            "Epoch 7/10 • Train Loss: 0.7937 • Dev Acc: 0.6056\n",
            "Epoch 8/10 • Train Loss: 0.7964 • Dev Acc: 0.6047\n",
            "Epoch 9/10 • Train Loss: 0.7780 • Dev Acc: 0.6209\n",
            "Epoch 10/10 • Train Loss: 0.7756 • Dev Acc: 0.6056\n",
            "Saved fine-tuned head weights to /content/drive/MyDrive/MELD/head_finetuned.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import numpy as np\n",
        "\n",
        "# ─── Paths ───────────────────────────────────────────────────────────────────\n",
        "base         = \"/content/drive/MyDrive/MELD\"\n",
        "base1 = \"/content/drive/MyDrive/MELD/segment_embeddings\"\n",
        "head_path    = f\"{base}/head_finetuned.pt\"\n",
        "fcls_path    = f\"{base1}/train_Fcls.pt\"\n",
        "output_csv   = f\"{base}/train_with_predictions.csv\"\n",
        "\n",
        "# ─── 1) Load Fcls features ────────────────────────────────────────────────────\n",
        "Fcls_train = torch.load(fcls_path, weights_only=True)  # [N, 3*H]\n",
        "\n",
        "# ─── 2) Define the MLP head architecture ─────────────────────────────────────\n",
        "class FineGrainedHead(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_labels, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.fc1  = nn.Linear(input_dim, hidden_dim)\n",
        "        self.act  = nn.Tanh()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.fc2  = nn.Linear(hidden_dim, num_labels)\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ─── 3) Instantiate and load saved weights ────────────────────────────────────\n",
        "hidden_size = 768\n",
        "input_dim   = 3 * hidden_size\n",
        "num_labels  = 7\n",
        "\n",
        "head = FineGrainedHead(input_dim, hidden_size, num_labels)\n",
        "head.load_state_dict(torch.load(head_path, map_location=\"cpu\"))\n",
        "head.eval()\n",
        "\n",
        "# ─── 4) Compute logits and probabilities ─────────────────────────────────────\n",
        "with torch.no_grad():\n",
        "    logits = head(Fcls_train)                   # [N, num_labels]\n",
        "    probs  = torch.softmax(logits, dim=1).cpu().numpy()  # [N, num_labels]\n",
        "\n",
        "# ─── 5) Map *all* confidences back to the DataFrame ───────────────────────────\n",
        "df = pd.read_csv(f\"{base}/train_with_context.csv\")\n",
        "\n",
        "EMOTIONS    = [\"anger\",\"disgust\",\"fear\",\"joy\",\"neutral\",\"sadness\",\"surprise\"]\n",
        "pred_ids    = np.argmax(probs, axis=1)\n",
        "pred_labels = [EMOTIONS[i] for i in pred_ids]\n",
        "pred_conf   = probs.max(axis=1)\n",
        "\n",
        "# 5a) keep the top prediction + its confidence\n",
        "df[\"pred_label\"]      = pred_labels\n",
        "df[\"pred_confidence\"] = pred_conf\n",
        "\n",
        "# 5b) add one column per emotion\n",
        "for idx, emo in enumerate(EMOTIONS):\n",
        "    df[f\"conf_{emo}\"] = probs[:, idx]\n",
        "\n",
        "# 6) Save the extended DataFrame\n",
        "df.to_csv(f\"{base}/train_with_all_confidences.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "gsl2u3UqEEqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ─── Paths ───────────────────────────────────────────────────────────────────\n",
        "base       = \"/content/drive/MyDrive/MELD\"\n",
        "base1      = \"/content/drive/MyDrive/MELD/segment_embeddings\"\n",
        "head_path  = f\"{base}/head_finetuned.pt\"\n",
        "fcls_dev   = f\"{base1}/dev_Fcls.pt\"\n",
        "input_csv  = f\"{base}/dev_with_context.csv\"\n",
        "output_csv = f\"{base}/dev_with_all_confidences.csv\"\n",
        "\n",
        "# ─── 1) Load dev Fcls features ────────────────────────────────────────────────\n",
        "#    Shape: [N_dev, 3*H]\n",
        "Fcls_dev_tensor = torch.load(fcls_dev, weights_only=True)\n",
        "\n",
        "# ─── 2) Define the MLP head architecture ─────────────────────────────────────\n",
        "class FineGrainedHead(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_labels, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.fc1  = nn.Linear(input_dim, hidden_dim)\n",
        "        self.act  = nn.Tanh()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.fc2  = nn.Linear(hidden_dim, num_labels)\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "hidden_size = 768\n",
        "input_dim   = 3 * hidden_size\n",
        "num_labels  = 7\n",
        "\n",
        "# Instantiate and load saved head weights\n",
        "head = FineGrainedHead(input_dim, hidden_size, num_labels)\n",
        "head.load_state_dict(torch.load(head_path, map_location=\"cpu\"))\n",
        "head.eval()\n",
        "\n",
        "# ─── 3) Compute logits and probabilities for dev ───────────────────────────────\n",
        "with torch.no_grad():\n",
        "    logits_dev = head(Fcls_dev_tensor)                     # [N_dev, 7]\n",
        "    probs_dev  = torch.softmax(logits_dev, dim=1).cpu().numpy()  # [N_dev, 7]\n",
        "\n",
        "# ─── 4) Load original dev DataFrame ─────────────────────────────────────────────\n",
        "df_dev = pd.read_csv(input_csv)\n",
        "\n",
        "EMOTIONS = [\"anger\",\"disgust\",\"fear\",\"joy\",\"neutral\",\"sadness\",\"surprise\"]\n",
        "\n",
        "# 4a) Top‐predicted label and its confidence\n",
        "pred_ids_dev    = np.argmax(probs_dev, axis=1)          # [N_dev]\n",
        "pred_labels_dev = [EMOTIONS[i] for i in pred_ids_dev]   # list of length N_dev\n",
        "pred_conf_dev   = probs_dev.max(axis=1)                 # [N_dev]\n",
        "\n",
        "df_dev[\"pred_label\"]      = pred_labels_dev\n",
        "df_dev[\"pred_confidence\"] = pred_conf_dev\n",
        "\n",
        "# 4b) One column per emotion confidence\n",
        "for idx, emo in enumerate(EMOTIONS):\n",
        "    df_dev[f\"conf_{emo}\"] = probs_dev[:, idx]\n",
        "\n",
        "# ─── 5) Save the dev DataFrame with all confidences ────────────────────────────\n",
        "df_dev.to_csv(output_csv, index=False)\n",
        "print(f\"✅ Saved dev confidences to: {output_csv}  (shape: {df_dev.shape})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9yV_3pyAm9O",
        "outputId": "04924e89-9684-459e-ad7a-590918038581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved dev confidences to: /content/drive/MyDrive/MELD/dev_with_all_confidences.csv  (shape: (1108, 21))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "base = \"/content/drive/MyDrive/MELD\"\n",
        "preds_file = os.path.join(base, \"train_with_predictions.csv\")\n",
        "p = 0.7\n",
        "\n",
        "emo_adverb = {\n",
        "    \"anger\":    \"angrily\",\n",
        "    \"disgust\":  \"disgustedly\",\n",
        "    \"fear\":     \"fearfully\",\n",
        "    \"joy\":      \"joyfully\",\n",
        "    \"neutral\":  \"neutrally\",\n",
        "    \"sadness\":  \"sadly\",\n",
        "    \"surprise\": \"surprisingly\"\n",
        "}\n",
        "\n",
        "# 1) Load your teacher‐annotated train CSV\n",
        "df = pd.read_csv(preds_file)\n",
        "df = df.sort_values([\"Dialogue_ID\",\"Utterance_ID\"]).reset_index(drop=True)\n",
        "\n",
        "# 2) Precompute each speaker’s turn‐list per dialogue\n",
        "#    A dict: (did, speaker) → sorted list of utterance_IDs they actually speak\n",
        "from collections import defaultdict\n",
        "speaker_turns = defaultdict(list)\n",
        "for _, row in df.iterrows():\n",
        "    speaker_turns[(row.Dialogue_ID, row.Speaker)].append(row.Utterance_ID)\n",
        "for key in speaker_turns:\n",
        "    speaker_turns[key].sort()\n",
        "\n",
        "# 3) Build single‐speaker student_input using speaker’s own ±1 window\n",
        "def build_ss_input(row):\n",
        "    did, uid, spk = row.Dialogue_ID, row.Utterance_ID, row.Speaker\n",
        "    # query\n",
        "    query = f\"<s> {spk} <mask> says: {row.Utterance} </s>\"\n",
        "\n",
        "    # find this speaker’s list and our position in it\n",
        "    turns = speaker_turns[(did, spk)]\n",
        "    pos   = turns.index(uid)\n",
        "\n",
        "    def fmt_speaker_context(pos2):\n",
        "        if pos2 < 0 or pos2 >= len(turns):\n",
        "            return \"\"\n",
        "        other_id = turns[pos2]\n",
        "        other    = df[(df.Dialogue_ID==did)&(df.Utterance_ID==other_id)].iloc[0]\n",
        "        text     = other.Utterance\n",
        "        conf     = other.pred_confidence\n",
        "        if conf >= p:\n",
        "            emo = other.pred_label\n",
        "            return f\"{spk} {emo_adverb[emo]} says: {text}\"\n",
        "        else:\n",
        "            return f\"{spk} says: {text}\"\n",
        "\n",
        "    # previous and next **by this same speaker**\n",
        "    past   = fmt_speaker_context(pos-1)\n",
        "    future = fmt_speaker_context(pos+1)\n",
        "\n",
        "    # stitch together\n",
        "    return \" \".join(seg for seg in (past, query, future) if seg)\n",
        "\n",
        "df[\"student_input\"] = df.apply(build_ss_input, axis=1)\n",
        "\n",
        "# 4) Save out\n",
        "out_csv = os.path.join(base, \"train_for_student_ss.csv\")\n",
        "df.to_csv(out_csv, index=False)\n",
        "print(f\"Saved single‐speaker (speaker‐window) inputs: {out_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvk6aqW4XbKR",
        "outputId": "b3fafb68-a5d8-4cfe-ae22-7138400b1cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved single‐speaker (speaker‐window) inputs: /content/drive/MyDrive/MELD/train_for_student_ss.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "# ─── CONFIG ───────────────────────────────────────────────────────────────────\n",
        "base       = \"/content/drive/MyDrive/MELD\"\n",
        "preds_file = os.path.join(base, \"train_with_all_confidences.csv\")  # <-- update this!\n",
        "out_file   = os.path.join(base, \"train_for_student_ss.csv\")\n",
        "p          = 0.7  # confidence threshold\n",
        "\n",
        "emo_adverb = {\n",
        "    \"anger\":    \"angrily\",\n",
        "    \"disgust\":  \"disgustedly\",\n",
        "    \"fear\":     \"fearfully\",\n",
        "    \"joy\":      \"joyfully\",\n",
        "    \"neutral\":  \"neutrally\",\n",
        "    \"sadness\":  \"sadly\",\n",
        "    \"surprise\": \"surprisingly\"\n",
        "}\n",
        "\n",
        "# ─── 1) Load and sort ──────────────────────────────────────────────────────────\n",
        "df = pd.read_csv(preds_file)\n",
        "df = df.sort_values([\"Dialogue_ID\", \"Utterance_ID\"]).reset_index(drop=True)\n",
        "\n",
        "# ─── 2) Precompute speaker‐turn lists ─────────────────────────────────────────\n",
        "speaker_turns = defaultdict(list)\n",
        "for _, row in df.iterrows():\n",
        "    speaker_turns[(row.Dialogue_ID, row.Speaker)].append(row.Utterance_ID)\n",
        "for key in speaker_turns:\n",
        "    speaker_turns[key].sort()\n",
        "\n",
        "# ─── 3) Build single‐speaker student_input ────────────────────────────────────\n",
        "def build_ss_input(row):\n",
        "    if row.pred_confidence < p:\n",
        "        return row.bert_input   # fallback if query low‐confidence\n",
        "\n",
        "    did, uid, spk = row.Dialogue_ID, row.Utterance_ID, row.Speaker\n",
        "    query = f\"<s> {spk} <mask> says: {row.Utterance} </s>\"\n",
        "\n",
        "    turns = speaker_turns[(did, spk)]\n",
        "    pos   = turns.index(uid)\n",
        "\n",
        "    def fmt(idx):\n",
        "        if idx < 0 or idx >= len(turns):\n",
        "            return \"\"\n",
        "        other_id = turns[idx]\n",
        "        other    = df[(df.Dialogue_ID==did)&(df.Utterance_ID==other_id)].iloc[0]\n",
        "        text     = other.Utterance\n",
        "        # always include context if query is confident\n",
        "        if row.pred_confidence >= p:\n",
        "            emo = other.pred_label\n",
        "            return f\"{spk} {emo_adverb[emo]} says: {text}\"\n",
        "        else:\n",
        "            return f\"{spk} says: {text}\"\n",
        "\n",
        "    past   = fmt(pos-1)\n",
        "    future = fmt(pos+1)\n",
        "    return \" \".join(seg for seg in (past, query, future) if seg)\n",
        "\n",
        "df[\"student_input\"] = df.apply(build_ss_input, axis=1)\n",
        "\n",
        "# ─── 4) Save out ───────────────────────────────────────────────────────────────\n",
        "df.to_csv(out_file, index=False)\n",
        "print(f\"Saved single-speaker student inputs (query-threshold) to:\\n{out_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drNYYGqbe8AN",
        "outputId": "0563f62a-e46b-439e-e663-7307ff2fd935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved single-speaker student inputs (query-threshold) to:\n",
            "/content/drive/MyDrive/MELD/train_for_student_ss.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "# ─── CONFIG ───────────────────────────────────────────────────────────────────\n",
        "base       = \"/content/drive/MyDrive/MELD\"\n",
        "preds_file = os.path.join(base, \"dev_with_all_confidences.csv\")  # <-- update this!\n",
        "out_file   = os.path.join(base, \"dev_for_student_ss.csv\")\n",
        "p          = 0.7  # confidence threshold\n",
        "\n",
        "emo_adverb = {\n",
        "    \"anger\":    \"angrily\",\n",
        "    \"disgust\":  \"disgustedly\",\n",
        "    \"fear\":     \"fearfully\",\n",
        "    \"joy\":      \"joyfully\",\n",
        "    \"neutral\":  \"neutrally\",\n",
        "    \"sadness\":  \"sadly\",\n",
        "    \"surprise\": \"surprisingly\"\n",
        "}\n",
        "\n",
        "# ─── 1) Load and sort ──────────────────────────────────────────────────────────\n",
        "df = pd.read_csv(preds_file)\n",
        "df = df.sort_values([\"Dialogue_ID\", \"Utterance_ID\"]).reset_index(drop=True)\n",
        "\n",
        "# ─── 2) Precompute speaker‐turn lists ─────────────────────────────────────────\n",
        "speaker_turns = defaultdict(list)\n",
        "for _, row in df.iterrows():\n",
        "    speaker_turns[(row.Dialogue_ID, row.Speaker)].append(row.Utterance_ID)\n",
        "for key in speaker_turns:\n",
        "    speaker_turns[key].sort()\n",
        "\n",
        "# ─── 3) Build single‐speaker student_input ────────────────────────────────────\n",
        "def build_ss_input(row):\n",
        "    if row.pred_confidence < p:\n",
        "        return row.bert_input   # fallback if query low‐confidence\n",
        "\n",
        "    did, uid, spk = row.Dialogue_ID, row.Utterance_ID, row.Speaker\n",
        "    query = f\"<s> {spk} <mask> says: {row.Utterance} </s>\"\n",
        "\n",
        "    turns = speaker_turns[(did, spk)]\n",
        "    pos   = turns.index(uid)\n",
        "\n",
        "    def fmt(idx):\n",
        "        if idx < 0 or idx >= len(turns):\n",
        "            return \"\"\n",
        "        other_id = turns[idx]\n",
        "        other    = df[(df.Dialogue_ID==did)&(df.Utterance_ID==other_id)].iloc[0]\n",
        "        text     = other.Utterance\n",
        "        # always include context if query is confident\n",
        "        if row.pred_confidence >= p:\n",
        "            emo = other.pred_label\n",
        "            return f\"{spk} {emo_adverb[emo]} says: {text}\"\n",
        "        else:\n",
        "            return f\"{spk} says: {text}\"\n",
        "\n",
        "    past   = fmt(pos-1)\n",
        "    future = fmt(pos+1)\n",
        "    return \" \".join(seg for seg in (past, query, future) if seg)\n",
        "\n",
        "df[\"student_input\"] = df.apply(build_ss_input, axis=1)\n",
        "\n",
        "# ─── 4) Save out ───────────────────────────────────────────────────────────────\n",
        "df.to_csv(out_file, index=False)\n",
        "print(f\"Saved single-speaker student inputs (query-threshold) to:\\n{out_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abn0lWnfAuMO",
        "outputId": "70c2cde3-ce53-44c0-c835-31415f639251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved single-speaker student inputs (query-threshold) to:\n",
            "/content/drive/MyDrive/MELD/dev_for_student_ss.csv\n"
          ]
        }
      ]
    }
  ]
}